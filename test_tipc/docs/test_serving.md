# PaddleServingé¢„æµ‹åŠŸèƒ½æµ‹è¯•

PaddleServingé¢„æµ‹åŠŸèƒ½æµ‹è¯•çš„ä¸»ç¨‹åºä¸º`test_serving_infer_python.sh`å’Œ`test_serving_infer_cpp.sh`ï¼Œå¯ä»¥æµ‹è¯•åŸºäºPaddleServingçš„éƒ¨ç½²åŠŸèƒ½ã€‚

## 1. æµ‹è¯•ç»“è®ºæ±‡æ€»

åŸºäºè®­ç»ƒæ˜¯å¦ä½¿ç”¨é‡åŒ–ï¼Œè¿›è¡Œæœ¬æµ‹è¯•çš„æ¨¡å‹å¯ä»¥åˆ†ä¸º`æ­£å¸¸æ¨¡å‹`å’Œ`é‡åŒ–æ¨¡å‹`ï¼Œè¿™ä¸¤ç±»æ¨¡å‹å¯¹åº”çš„Servingé¢„æµ‹åŠŸèƒ½æ±‡æ€»å¦‚ä¸‹ï¼š

| æ¨¡å‹ç±»å‹ |device | batchsize | tensorrt | mkldnn | cpuå¤šçº¿ç¨‹ |
|  ----   |  ---- |   ----   |  :----:  |   :----:   |  :----:  |
| æ­£å¸¸æ¨¡å‹ | GPU | 1/6 | fp32/fp16 | - | - |
| æ­£å¸¸æ¨¡å‹ | CPU | 1/6 | - | fp32 | æ”¯æŒ |
| é‡åŒ–æ¨¡å‹ | GPU | 1/6 | int8 | - | - |
| é‡åŒ–æ¨¡å‹ | CPU | 1/6 | - | int8 | æ”¯æŒ |

## 2. æµ‹è¯•æµç¨‹
è¿è¡Œç¯å¢ƒé…ç½®è¯·å‚è€ƒ[æ–‡æ¡£](./install.md)çš„å†…å®¹é…ç½®TIPCçš„è¿è¡Œç¯å¢ƒã€‚

### 2.1 åŠŸèƒ½æµ‹è¯•
**python serving**
å…ˆè¿è¡Œ`prepare.sh`å‡†å¤‡æ•°æ®å’Œæ¨¡å‹ï¼Œç„¶åè¿è¡Œ`test_serving_infer_python.sh`è¿›è¡Œæµ‹è¯•ï¼Œæœ€ç»ˆåœ¨```test_tipc/output/{model_name}/serving_infer/python```ç›®å½•ä¸‹ç”Ÿæˆ`python_*.log`åç¼€çš„æ—¥å¿—æ–‡ä»¶ã€‚

```shell
bash test_tipc/prepare.sh ./test_tipc/configs/ch_PP-OCRv2/model_linux_gpu_normal_normal_serving_python_linux_gpu_cpu.txt "serving_infer"

# ç”¨æ³•:
bash test_tipc/test_serving_infer_python.sh ./test_tipc/configs/ch_PP-OCRv2/model_linux_gpu_normal_normal_serving_python_linux_gpu_cpu.txt "serving_infer"
```  
**cpp serving**
å…ˆè¿è¡Œ`prepare.sh`å‡†å¤‡æ•°æ®å’Œæ¨¡å‹ï¼Œç„¶åè¿è¡Œ`test_serving_infer_cpp.sh`è¿›è¡Œæµ‹è¯•ï¼Œæœ€ç»ˆåœ¨```test_tipc/output/{model_name}/serving_infer/cpp```ç›®å½•ä¸‹ç”Ÿæˆ`cpp_*.log`åç¼€çš„æ—¥å¿—æ–‡ä»¶ã€‚

```shell
bash test_tipc/prepare.sh ./test_tipc/configs/ch_PP-OCRv2/model_linux_gpu_normal_normal_serving_cpp_linux_gpu_cpu.txt "serving_infer"

# ç”¨æ³•:
bash test_tipc/test_serving_infer_cpp.sh ./test_tipc/configs/ch_PP-OCRv2/model_linux_gpu_normal_normal_serving_cpp_linux_gpu_cpu.txt "serving_infer"
```  

#### è¿è¡Œç»“æœ

å„æµ‹è¯•çš„è¿è¡Œæƒ…å†µä¼šæ‰“å°åœ¨ `test_tipc/output/{model_name}/serving_infer/python(cpp)/results_python(cpp)_serving.log` ä¸­ï¼š
è¿è¡ŒæˆåŠŸæ—¶ä¼šè¾“å‡ºï¼š

```
Run successfully with command - ch_PP-OCRv2_rec - nohup python3.7 web_service_rec.py --config=config.yml --opt op.rec.concurrency="1" op.det.local_service_conf.devices= op.det.local_service_conf.use_mkldnn=False op.det.local_service_conf.thread_num=6 op.rec.local_service_conf.model_config=ppocr_rec_v2_serving > ./test_tipc/output/ch_PP-OCRv2_rec/serving_infer/python/python_server_cpu_usemkldnn_False_threads_6.log 2>&1 &!
Run successfully with command - ch_PP-OCRv2_rec - python3.7 pipeline_http_client.py --det=False --image_dir=../../inference/rec_inference > ./test_tipc/output/ch_PP-OCRv2_rec/serving_infer/python/python_client_cpu_pipeline_http_usemkldnn_False_threads_6_batchsize_1.log 2>&1 !
...
```

è¿è¡Œå¤±è´¥æ—¶ä¼šè¾“å‡ºï¼š

```
Run failed with command - ch_PP-OCRv2_rec - nohup python3.7 web_service_rec.py --config=config.yml --opt op.rec.concurrency="1" op.det.local_service_conf.devices= op.det.local_service_conf.use_mkldnn=False op.det.local_service_conf.thread_num=6 op.rec.local_service_conf.model_config=ppocr_rec_v2_serving > ./test_tipc/output/ch_PP-OCRv2_rec/serving_infer/python/python_server_cpu_usemkldnn_False_threads_6.log 2>&1 &!
Run failed with command - ch_PP-OCRv2_rec - python3.7 pipeline_http_client.py --det=False --image_dir=../../inference/rec_inference > ./test_tipc/output/ch_PP-OCRv2_rec/serving_infer/python/python_client_cpu_pipeline_http_usemkldnn_False_threads_6_batchsize_1.log 2>&1 !
...
```

è¯¦ç»†çš„é¢„æµ‹ç»“æœä¼šå­˜åœ¨ test_tipc/output/{model_name}/serving_infer/python(cpp)/ æ–‡ä»¶å¤¹ä¸‹


## 3. æ›´å¤šæ•™ç¨‹

æœ¬æ–‡æ¡£ä¸ºåŠŸèƒ½æµ‹è¯•ç”¨ï¼Œæ›´è¯¦ç»†çš„Servingé¢„æµ‹ä½¿ç”¨æ•™ç¨‹è¯·å‚è€ƒï¼š[PPOCR æœåŠ¡åŒ–éƒ¨ç½²](https://github.com/PaddlePaddle/PaddleOCR/blob/dygraph/deploy/pdserving/README_CN.md)  
