---
typora-copy-images-to: images
comments: true
---

## 1. é¡¹ç›®ä»‹ç»

å¼¯æ›²æ–‡å­—è¯†åˆ«åœ¨OCRä»»åŠ¡ä¸­æœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼Œæ¯”å¦‚ï¼šè‡ªç„¶åœºæ™¯ä¸‹çš„æ‹›ç‰Œï¼Œè‰ºæœ¯æ–‡å­—ï¼Œä»¥åŠå¸¸è§çš„å°ç« æ–‡å­—è¯†åˆ«ã€‚

åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œå°†ä»¥å°ç« è¯†åˆ«ä»»åŠ¡ä¸ºä¾‹ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨PaddleDetectionå’ŒPaddleOCRå®Œæˆå°ç« æ£€æµ‹å’Œå°ç« æ–‡å­—è¯†åˆ«ä»»åŠ¡ã€‚

é¡¹ç›®éš¾ç‚¹ï¼š

1. ç¼ºä¹è®­ç»ƒæ•°æ®
2. å›¾åƒè´¨é‡å‚å·®ä¸é½ï¼Œå›¾åƒæ¨¡ç³Šï¼Œæ–‡å­—ä¸æ¸…æ™°

é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œæœ¬é¡¹ç›®é€‰ç”¨PaddleOCRé‡Œçš„PPOCRLabelå·¥å…·å®Œæˆæ•°æ®æ ‡æ³¨ã€‚åŸºäºPaddleDetectionå®Œæˆå°ç« åŒºåŸŸæ£€æµ‹ï¼Œç„¶åé€šè¿‡PaddleOCRé‡Œçš„ç«¯å¯¹ç«¯OCRç®—æ³•å’Œä¸¤é˜¶æ®µOCRç®—æ³•åˆ†åˆ«å®Œæˆå°ç« æ–‡å­—è¯†åˆ«ä»»åŠ¡ã€‚ä¸åŒä»»åŠ¡çš„ç²¾åº¦æ•ˆæœå¦‚ä¸‹ï¼š

| ä»»åŠ¡ | è®­ç»ƒæ•°æ®æ•°é‡ | ç²¾åº¦ |
| -------- | - | -------- |
| å°ç« æ£€æµ‹ | 1000    | 95.00%  |
| å°ç« æ–‡å­—è¯†åˆ«-ç«¯å¯¹ç«¯OCRæ–¹æ³• | 700    | 47.00%  |
| å°ç« æ–‡å­—è¯†åˆ«-ä¸¤é˜¶æ®µOCRæ–¹æ³• |  700   | 55.00%  |

ç‚¹å‡»è¿›å…¥ [AI Studio é¡¹ç›®](https://aistudio.baidu.com/aistudio/projectdetail/4586113)

## 2. ç¯å¢ƒæ­å»º

æœ¬é¡¹ç›®éœ€è¦å‡†å¤‡PaddleDetectionå’ŒPaddleOCRçš„é¡¹ç›®è¿è¡Œç¯å¢ƒï¼Œå…¶ä¸­PaddleDetectionç”¨äºå®ç°å°ç« æ£€æµ‹ä»»åŠ¡ï¼ŒPaddleOCRç”¨äºå®ç°æ–‡å­—è¯†åˆ«ä»»åŠ¡

### 2.1 å‡†å¤‡PaddleDetectionç¯å¢ƒ

ä¸‹è½½PaddleDetectionä»£ç ï¼š

```bash linenums="1"
!git clone https://github.com/PaddlePaddle/PaddleDetection.git
# å¦‚æœå…‹éš†githubä»£ç è¾ƒæ…¢ï¼Œè¯·ä»giteeä¸Šå…‹éš†ä»£ç 
#git clone https://gitee.com/PaddlePaddle/PaddleDetection.git
```

å®‰è£…PaddleDetectionä¾èµ–

```bash linenums="1"
!cd PaddleDetection && pip install -r requirements.txt
```

### 2.2 å‡†å¤‡PaddleOCRç¯å¢ƒ

ä¸‹è½½PaddleOCRä»£ç ï¼š

```bash linenums="1"
!git clone https://github.com/PaddlePaddle/PaddleOCR.git
# å¦‚æœå…‹éš†githubä»£ç è¾ƒæ…¢ï¼Œè¯·ä»giteeä¸Šå…‹éš†ä»£ç 
#git clone https://gitee.com/PaddlePaddle/PaddleOCR.git
```

å®‰è£…PaddleOCRä¾èµ–

```bash linenums="1"
!cd PaddleOCR && git checkout dygraph  && pip install -r requirements.txt
```

## 3. æ•°æ®é›†å‡†å¤‡

### 3.1 æ•°æ®æ ‡æ³¨

æœ¬é¡¹ç›®ä¸­ä½¿ç”¨[PPOCRLabel](https://github.com/PFCCLab/PPOCRLabel)å·¥å…·æ ‡æ³¨å°ç« æ£€æµ‹æ•°æ®ï¼Œæ ‡æ³¨å†…å®¹åŒ…æ‹¬å°ç« çš„ä½ç½®ä»¥åŠå°ç« ä¸­æ–‡å­—çš„ä½ç½®å’Œæ–‡å­—å†…å®¹ã€‚

æ³¨ï¼šPPOCRLabelçš„ä½¿ç”¨æ–¹æ³•å‚è€ƒ[æ–‡æ¡£](https://github.com/PFCCLab/PPOCRLabel)ã€‚

PPOCRlabelæ ‡æ³¨å°ç« æ•°æ®æ­¥éª¤ï¼š

- æ‰“å¼€æ•°æ®é›†æ‰€åœ¨æ–‡ä»¶å¤¹
- æŒ‰ä¸‹å¿«æ·é”®Qè¿›è¡Œ4ç‚¹ï¼ˆå¤šç‚¹ï¼‰æ ‡æ³¨â€”â€”é’ˆå¯¹å°ç« æ–‡æœ¬è¯†åˆ«ï¼Œ
  - å°ç« å¼¯æ›²æ–‡å­—åŒ…å›´æ¡†é‡‡ç”¨å¶æ•°ç‚¹æ ‡æ³¨ï¼ˆæ¯”å¦‚4ç‚¹ï¼Œ8ç‚¹ï¼Œ16ç‚¹ï¼‰ï¼ŒæŒ‰ç…§é˜…è¯»é¡ºåºï¼Œä»¥16ç‚¹æ ‡æ³¨ä¸ºä¾‹ï¼Œä»æ–‡å­—å·¦ä¸Šæ–¹å¼€å§‹æ ‡æ³¨->åˆ°æ–‡å­—å³ä¸Šæ–¹æ ‡æ³¨8ä¸ªç‚¹->åˆ°æ–‡å­—å³ä¸‹æ–¹->æ–‡å­—å·¦ä¸‹æ–¹8ä¸ªç‚¹ï¼Œä¸€å…±8ä¸ªç‚¹ï¼Œå½¢æˆåŒ…å›´æ›²çº¿ï¼Œå‚è€ƒä¸‹å›¾ã€‚å¦‚æœæ–‡å­—å¼¯æ›²ç¨‹åº¦ä¸é«˜ï¼Œä¸ºäº†å‡å°æ ‡æ³¨å·¥ä½œé‡ï¼Œå¯ä»¥é‡‡ç”¨4ç‚¹ã€8ç‚¹æ ‡æ³¨ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ–‡å­—ä¸Šä¸‹ç‚¹æ•°ç›¸åŒã€‚ï¼ˆæ€»ç‚¹æ•°å°½é‡ä¸è¦è¶…è¿‡18ä¸ªï¼‰
  - å¯¹äºéœ€è¦è¯†åˆ«çš„å°ç« ä¸­éå¼¯æ›²æ–‡å­—ï¼Œé‡‡ç”¨4ç‚¹æ¡†æ ‡æ³¨å³å¯
  - å¯¹åº”åŒ…å›´æ¡†çš„æ–‡å­—éƒ¨åˆ†é»˜è®¤æ˜¯â€å¾…è¯†åˆ«â€ï¼Œéœ€è¦ä¿®æ”¹ä¸ºåŒ…å›´æ¡†å†…çš„å…·ä½“æ–‡å­—å†…å®¹
- å¿«æ·é”®Wè¿›è¡ŒçŸ©å½¢æ ‡æ³¨â€”â€”é’ˆå¯¹å°ç« åŒºåŸŸæ£€æµ‹ï¼Œå°ç« æ£€æµ‹åŒºåŸŸä¿è¯æ ‡æ³¨æ¡†åŒ…å›´æ•´ä¸ªå°ç« ï¼ŒåŒ…å›´æ¡†å¯¹åº”æ–‡å­—å¯ä»¥è®¾ç½®ä¸º'å°ç« åŒºåŸŸ'ï¼Œæ–¹ä¾¿åç»­å¤„ç†ã€‚
- é’ˆå¯¹å°ç« ä¸­çš„æ°´å¹³æ–‡å­—å¯ä»¥è§†æƒ…å†µè€ƒè™‘çŸ©å½¢æˆ–å››ç‚¹æ ‡æ³¨ï¼šä¿è¯æŒ‰è¡Œæ ‡æ³¨å³å¯ã€‚å¦‚æœèƒŒæ™¯æ–‡å­—ä¸å°ç« æ–‡å­—æ¯”è¾ƒæ¥è¿‘ï¼Œæ ‡æ³¨æ—¶å°½é‡é¿å¼€èƒŒæ™¯æ–‡å­—ã€‚
- æ ‡æ³¨å®Œæˆåä¿®æ”¹å³ä¾§æ–‡æœ¬ç»“æœï¼Œç¡®è®¤æ— è¯¯åç‚¹å‡»ä¸‹æ–¹checkï¼ˆæˆ–CTRL+V)ï¼Œç¡®è®¤æœ¬å¼ å›¾ç‰‡çš„æ ‡æ³¨ã€‚
- æ‰€æœ‰å›¾ç‰‡æ ‡æ³¨å®Œæˆåï¼Œåœ¨é¡¶éƒ¨èœå•æ ç‚¹å‡»File -> Export Labelå¯¼å‡ºlabel.txtã€‚

æ ‡æ³¨å®Œæˆåï¼Œå¯è§†åŒ–æ•ˆæœå¦‚ä¸‹ï¼š
![](./images/f5acbc4f50dd401a8f535ed6a263f94b0edff82c1aed4285836a9ead989b9c13.png)

æ•°æ®æ ‡æ³¨å®Œæˆåï¼Œæ ‡ç­¾ä¸­åŒ…å«å°ç« æ£€æµ‹çš„æ ‡æ³¨å’Œå°ç« æ–‡å­—è¯†åˆ«çš„æ ‡æ³¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```text linenums="1"
img/1.png    [{"transcription": "å°ç« åŒºåŸŸ", "points": [[87, 245], [214, 245], [214, 369], [87, 369]], "difficult": false}, {"transcription": "å›½å®¶ç¨åŠ¡æ€»å±€æ³¸æ°´å¸‚ç¨åŠ¡å±€ç¬¬äºŒç¨åŠ¡åˆ†å±€", "points": [[110, 314], [116, 290], [131, 275], [152, 273], [170, 277], [181, 289], [186, 303], [186, 312], [201, 311], [198, 289], [189, 272], [175, 259], [152, 252], [124, 257], [100, 280], [94, 312]], "difficult": false}, {"transcription": "å¾ç¨ä¸“ç”¨ç« ", "points": [[117, 334], [183, 334], [183, 352], [117, 352]], "difficult": false}]
```

æ ‡æ³¨ä¸­åŒ…å«è¡¨ç¤º'å°ç« åŒºåŸŸ'çš„åæ ‡å’Œ'å°ç« æ–‡å­—'åæ ‡ä»¥åŠæ–‡å­—å†…å®¹ã€‚

### 3.2 æ•°æ®å¤„ç†

æ ‡æ³¨æ—¶ä¸ºäº†æ–¹ä¾¿æ ‡æ³¨ï¼Œæ²¡æœ‰åŒºåˆ†å°ç« åŒºåŸŸçš„æ ‡æ³¨æ¡†å’Œæ–‡å­—åŒºåŸŸçš„æ ‡æ³¨æ¡†ï¼Œå¯ä»¥é€šè¿‡pythonä»£ç å®Œæˆæ ‡ç­¾çš„åˆ’åˆ†ã€‚

åœ¨æœ¬é¡¹ç›®çš„'/home/aistudio/work/seal_labeled_datas'ç›®å½•ä¸‹ï¼Œå­˜æ”¾äº†æ ‡æ³¨çš„æ•°æ®ç¤ºä¾‹ï¼Œå¦‚ä¸‹ï¼š

![](./images/3d762970e2184177a2c633695a31029332a4cd805631430ea797309492e45402.jpeg)

æ ‡ç­¾æ–‡ä»¶'/home/aistudio/work/seal_labeled_datas/Label.txt'ä¸­çš„æ ‡æ³¨å†…å®¹å¦‚ä¸‹ï¼š

```text linenums="1"
img/test1.png   [{"transcription": "å¾…è¯†åˆ«", "points": [[408, 232], [537, 232], [537, 352], [408, 352]], "difficult": false}, {"transcription": "ç”µå­å›å•", "points": [[437, 305], [504, 305], [504, 322], [437, 322]], "difficult": false}, {"transcription": "äº‘å—çœå†œæ‘ä¿¡ç”¨ç¤¾", "points": [[417, 290], [434, 295], [438, 281], [446, 267], [455, 261], [472, 258], [489, 264], [498, 277], [502, 295], [526, 289], [518, 267], [503, 249], [475, 232], [446, 239], [429, 255], [418, 275]], "difficult": false}, {"transcription": "ä¸“ç”¨ç« ", "points": [[437, 319], [503, 319], [503, 338], [437, 338]], "difficult": false}]
```

ä¸ºäº†æ–¹ä¾¿è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡pythonä»£ç å°†ç”¨äºè®­ç»ƒå°ç« æ£€æµ‹å’Œè®­ç»ƒå°ç« æ–‡å­—è¯†åˆ«çš„æ ‡æ³¨åŒºåˆ†å¼€ã€‚

<details>

```python linenums="1"
import numpy as np
import json
import cv2
import os
from shapely.geometry import Polygon


def poly2box(poly):
    xmin = np.min(np.array(poly)[:, 0])
    ymin = np.min(np.array(poly)[:, 1])
    xmax = np.max(np.array(poly)[:, 0])
    ymax = np.max(np.array(poly)[:, 1])
    return np.array([[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]])


def draw_text_det_res(dt_boxes, src_im, color=(255, 255, 0)):
    for box in dt_boxes:
        box = np.array(box).astype(np.int32).reshape(-1, 2)
        cv2.polylines(src_im, [box], True, color=color, thickness=2)
    return src_im

class LabelDecode(object):
    def __init__(self, **kwargs):
        pass

    def __call__(self, data):
        label = json.loads(data['label'])

        nBox = len(label)
        seal_boxes = self.get_seal_boxes(label)

        gt_label = []

        for seal_box in seal_boxes:
            seal_anno = {'seal_box': seal_box}
            boxes, txts, txt_tags = [], [], []

            for bno in range(0, nBox):
                box = label[bno]['points']
                txt = label[bno]['transcription']
                try:
                    ints = self.get_intersection(box, seal_box)
                except Exception as E:
                    print(E)
                    continue

                if abs(Polygon(box).area - self.get_intersection(box, seal_box)) < 1e-3 and \
                    abs(Polygon(box).area - self.get_union(box, seal_box)) > 1e-3:

                    boxes.append(box)
                    txts.append(txt)
                    if txt in ['*', '###', 'å¾…è¯†åˆ«']:
                        txt_tags.append(True)
                    else:
                        txt_tags.append(False)

            seal_anno['polys'] = boxes
            seal_anno['texts'] = txts
            seal_anno['ignore_tags'] = txt_tags

            gt_label.append(seal_anno)

        return gt_label

    def get_seal_boxes(self, label):

        nBox = len(label)
        seal_box = []
        for bno in range(0, nBox):
            box = label[bno]['points']
            if len(box) == 4:
                seal_box.append(box)

        if len(seal_box) == 0:
            return None

        seal_box = self.valid_seal_box(seal_box)
        return seal_box


    def is_seal_box(self, box, boxes):
        is_seal = True
        for poly in boxes:
            if list(box.shape()) != list(box.shape.shape()):
                if abs(Polygon(box).area - self.get_intersection(box, poly)) < 1e-3:
                    return False
            else:
                if np.sum(np.array(box) - np.array(poly)) < 1e-3:
                    # continue when the box is same with poly
                    continue
                if abs(Polygon(box).area - self.get_intersection(box, poly)) < 1e-3:
                    return False
        return is_seal


    def valid_seal_box(self, boxes):
        if len(boxes) == 1:
            return boxes

        new_boxes = []
        flag = True
        for k in range(0, len(boxes)):
            flag = True
            tmp_box = boxes[k]
            for i in range(0, len(boxes)):
                if k == i: continue
                if abs(Polygon(tmp_box).area - self.get_intersection(tmp_box, boxes[i])) < 1e-3:
                    flag = False
                    continue
            if flag:
                new_boxes.append(tmp_box)

        return new_boxes


    def get_union(self, pD, pG):
        return Polygon(pD).union(Polygon(pG)).area

    def get_intersection_over_union(self, pD, pG):
        return get_intersection(pD, pG) / get_union(pD, pG)

    def get_intersection(self, pD, pG):
        return Polygon(pD).intersection(Polygon(pG)).area

    def expand_points_num(self, boxes):
        max_points_num = 0
        for box in boxes:
            if len(box) > max_points_num:
                max_points_num = len(box)
        ex_boxes = []
        for box in boxes:
            ex_box = box + [box[-1]] * (max_points_num - len(box))
            ex_boxes.append(ex_box)
        return ex_boxes


def gen_extract_label(data_dir, label_file, seal_gt, seal_ppocr_gt):
    label_decode_func = LabelDecode()
    gts = open(label_file, "r").readlines()

    seal_gt_list = []
    seal_ppocr_list = []

    for idx, line in enumerate(gts):
        img_path, label = line.strip().split("\t")
        data = {'label': label, 'img_path':img_path}
        res = label_decode_func(data)
        src_img = cv2.imread(os.path.join(data_dir, img_path))
        if res is None:
            print("ERROR! res is None!")
            continue

        anno = []
        for i, gt in enumerate(res):
            # print(i, box, type(box), )
            anno.append({'polys': gt['seal_box'], 'cls':1})

        seal_gt_list.append(f"{img_path}\t{json.dumps(anno)}\n")
        seal_ppocr_list.append(f"{img_path}\t{json.dumps(res)}\n")

    if not os.path.exists(os.path.dirname(seal_gt)):
        os.makedirs(os.path.dirname(seal_gt))
    if not os.path.exists(os.path.dirname(seal_ppocr_gt)):
        os.makedirs(os.path.dirname(seal_ppocr_gt))

    with open(seal_gt, "w") as f:
        f.writelines(seal_gt_list)
        f.close()

    with open(seal_ppocr_gt, 'w') as f:
        f.writelines(seal_ppocr_list)
        f.close()

def vis_seal_ppocr(data_dir, label_file, save_dir):

    datas = open(label_file, 'r').readlines()
    for idx, line in enumerate(datas):
        img_path, label = line.strip().split('\t')
        img_path = os.path.join(data_dir, img_path)

        label = json.loads(label)
        src_im = cv2.imread(img_path)
        if src_im is None:
            continue

        for anno in label:
            seal_box = anno['seal_box']
            txt_boxes = anno['polys']

             # vis seal box
            src_im = draw_text_det_res([seal_box], src_im, color=(255, 255, 0))
            src_im = draw_text_det_res(txt_boxes, src_im, color=(255, 0, 0))

        save_path = os.path.join(save_dir, os.path.basename(img_path))
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        # print(src_im.shape)
        cv2.imwrite(save_path, src_im)


def draw_html(img_dir, save_name):
    import glob

    images_dir = glob.glob(img_dir + "/*")
    print(len(images_dir))

    html_path = save_name
    with open(html_path, 'w') as html:
        html.write('<html>\n<body>\n')
        html.write('<table border="1">\n')
        html.write("<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />")

        html.write("<tr>\n")
        html.write(f'<td> \n GT')

        for i, filename in enumerate(sorted(images_dir)):
            if filename.endswith("txt"): continue
            print(filename)

            base = "{}".format(filename)
            if True:
                html.write("<tr>\n")
                html.write(f'<td> {filename}\n GT')
                html.write('<td>GT 310\n<img src="%s" width=640></td>' % (base))
                html.write("</tr>\n")

        html.write('<style>\n')
        html.write('span {\n')
        html.write('    color: red;\n')
        html.write('}\n')
        html.write('</style>\n')
        html.write('</table>\n')
        html.write('</html>\n</body>\n')
    print("ok")


def crop_seal_from_img(label_file, data_dir, save_dir, save_gt_path):

    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    datas = open(label_file, 'r').readlines()
    all_gts = []
    count = 0
    for idx, line in enumerate(datas):
        img_path, label = line.strip().split('\t')
        img_path = os.path.join(data_dir, img_path)

        label = json.loads(label)
        src_im = cv2.imread(img_path)
        if src_im is None:
            continue

        for c, anno in enumerate(label):
            seal_poly = anno['seal_box']
            txt_boxes = anno['polys']
            txts = anno['texts']
            ignore_tags = anno['ignore_tags']

            box = poly2box(seal_poly)
            img_crop = src_im[box[0][1]:box[2][1], box[0][0]:box[2][0], :]

            save_path = os.path.join(save_dir, f"{idx}_{c}.jpg")
            cv2.imwrite(save_path, np.array(img_crop))

            img_gt = []
            for i in range(len(txts)):
                txt_boxes_crop = np.array(txt_boxes[i])
                txt_boxes_crop[:, 1] -= box[0, 1]
                txt_boxes_crop[:, 0] -= box[0, 0]
                img_gt.append({'transcription': txts[i], "points": txt_boxes_crop.tolist(), "ignore_tag": ignore_tags[i]})

            if len(img_gt) >= 1:
                count += 1
            save_gt = f"{os.path.basename(save_path)}\t{json.dumps(img_gt)}\n"

            all_gts.append(save_gt)

    print(f"The num of all image: {len(all_gts)}, and the number of useful image: {count}")
    if not os.path.exists(os.path.dirname(save_gt_path)):
        os.makedirs(os.path.dirname(save_gt_path))

    with open(save_gt_path, "w") as f:
        f.writelines(all_gts)
        f.close()
    print("Done")


if __name__ == "__main__":
    # æ•°æ®å¤„ç†
    gen_extract_label("./seal_labeled_datas", "./seal_labeled_datas/Label.txt", "./seal_ppocr_gt/seal_det_img.txt", "./seal_ppocr_gt/seal_ppocr_img.txt")
    vis_seal_ppocr("./seal_labeled_datas", "./seal_ppocr_gt/seal_ppocr_img.txt", "./seal_ppocr_gt/seal_ppocr_vis/")
    draw_html("./seal_ppocr_gt/seal_ppocr_vis/", "./vis_seal_ppocr.html")
    seal_ppocr_img_label = "./seal_ppocr_gt/seal_ppocr_img.txt"
    crop_seal_from_img(seal_ppocr_img_label, "./seal_labeled_datas/", "./seal_img_crop", "./seal_img_crop/label.txt")
```

</details>

å¤„ç†å®Œæˆåï¼Œç”Ÿæˆçš„æ–‡ä»¶å¦‚ä¸‹ï¼š

```text linenums="1"
â”œâ”€â”€ seal_img_crop/
â”‚   â”œâ”€â”€ 0_0.jpg
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ label.txt
â”œâ”€â”€ seal_ppocr_gt/
â”‚   â”œâ”€â”€ seal_det_img.txt
â”‚   â”œâ”€â”€ seal_ppocr_img.txt
â”‚   â””â”€â”€ seal_ppocr_vis/
â”‚       â”œâ”€â”€ test1.png
â”‚       â”œâ”€â”€ ...
â””â”€â”€ vis_seal_ppocr.html

```

å…¶ä¸­`seal_img_crop/label.txt`æ–‡ä»¶ä¸ºå°ç« è¯†åˆ«æ ‡ç­¾æ–‡ä»¶ï¼Œå…¶å†…å®¹æ ¼å¼ä¸ºï¼š

```text linenums="1"
0_0.jpg    [{"transcription": "\u7535\u5b50\u56de\u5355", "points": [[29, 73], [96, 73], [96, 90], [29, 90]], "ignore_tag": false}, {"transcription": "\u4e91\u5357\u7701\u519c\u6751\u4fe1\u7528\u793e", "points": [[9, 58], [26, 63], [30, 49], [38, 35], [47, 29], [64, 26], [81, 32], [90, 45], [94, 63], [118, 57], [110, 35], [95, 17], [67, 0], [38, 7], [21, 23], [10, 43]], "ignore_tag": false}, {"transcription": "\u4e13\u7528\u7ae0", "points": [[29, 87], [95, 87], [95, 106], [29, 106]], "ignore_tag": false}]
```

å¯ä»¥ç›´æ¥ç”¨äºPaddleOCRçš„PGNetç®—æ³•çš„è®­ç»ƒã€‚

`seal_ppocr_gt/seal_det_img.txt`ä¸ºå°ç« æ£€æµ‹æ ‡ç­¾æ–‡ä»¶ï¼Œå…¶å†…å®¹æ ¼å¼ä¸ºï¼š

```text linenums="1"
img/test1.png    [{"polys": [[408, 232], [537, 232], [537, 352], [408, 352]], "cls": 1}]
```

ä¸ºäº†ä½¿ç”¨PaddleDetectionå·¥å…·å®Œæˆå°ç« æ£€æµ‹æ¨¡å‹çš„è®­ç»ƒï¼Œéœ€è¦å°†`seal_det_img.txt`è½¬æ¢ä¸ºCOCOæˆ–è€…VOCçš„æ•°æ®æ ‡æ³¨æ ¼å¼ã€‚

å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸‹è¿°ä»£ç å°†å°ç« æ£€æµ‹æ ‡æ³¨è½¬æ¢æˆVOCæ ¼å¼ã€‚

<details>

```python linenums="1"
import numpy as np
import json
import cv2
import os
from shapely.geometry import Polygon

seal_train_gt = "./seal_ppocr_gt/seal_det_img.txt"
# æ³¨ï¼šä»…ç”¨äºç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨ä¸­éœ€è¦åˆ†åˆ«è½¬æ¢è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ‡ç­¾
seal_valid_gt = "./seal_ppocr_gt/seal_det_img.txt"

def gen_main_train_txt(mode='train'):
    if mode == "train":
        file_path = seal_train_gt
    if mode in ['valid', 'test']:
        file_path = seal_valid_gt

    save_path = f"./seal_VOC/ImageSets/Main/{mode}.txt"
    save_train_path = f"./seal_VOC/{mode}.txt"
    if not os.path.exists(os.path.dirname(save_path)):
        os.makedirs(os.path.dirname(save_path))

    datas = open(file_path, 'r').readlines()
    img_names = []
    train_names = []
    for line in datas:
        img_name = line.strip().split('\t')[0]
        img_name = os.path.basename(img_name)
        (i_name, extension) = os.path.splitext(img_name)
        t_name = 'JPEGImages/'+str(img_name)+' '+'Annotations/'+str(i_name)+'.xml\n'
        train_names.append(t_name)
        img_names.append(i_name + "\n")

    with open(save_train_path, "w") as f:
        f.writelines(train_names)
        f.close()

    with open(save_path, "w") as f:
        f.writelines(img_names)
        f.close()

    print(f"{mode} save done")


def gen_xml_label(mode='train'):
    if mode == "train":
        file_path = seal_train_gt
    if mode in ['valid', 'test']:
        file_path = seal_valid_gt

    datas = open(file_path, 'r').readlines()
    img_names = []
    train_names = []
    anno_path = "./seal_VOC/Annotations"
    img_path = "./seal_VOC/JPEGImages"

    if not os.path.exists(anno_path):
        os.makedirs(anno_path)
    if not os.path.exists(img_path):
        os.makedirs(img_path)

    for idx, line in enumerate(datas):
        img_name, label = line.strip().split('\t')
        img = cv2.imread(os.path.join("./seal_labeled_datas", img_name))
        cv2.imwrite(os.path.join(img_path, os.path.basename(img_name)), img)
        height, width, c = img.shape
        img_name = os.path.basename(img_name)
        (i_name, extension) = os.path.splitext(img_name)
        label = json.loads(label)

        xml_file = open(("./seal_VOC/Annotations" + '/' + i_name + '.xml'), 'w')
        xml_file.write('<annotation>\n')
        xml_file.write('    <folder>seal_VOC</folder>\n')
        xml_file.write('    <filename>' + str(img_name) + '</filename>\n')
        xml_file.write('    <path>' + 'Annotations/' + str(img_name) + '</path>\n')
        xml_file.write('    <size>\n')
        xml_file.write('        <width>' + str(width) + '</width>\n')
        xml_file.write('        <height>' + str(height) + '</height>\n')
        xml_file.write('        <depth>3</depth>\n')
        xml_file.write('    </size>\n')
        xml_file.write('    <segmented>0</segmented>\n')

        for anno in label:
            poly = anno['polys']
            if anno['cls'] == 1:
                gt_cls = 'redseal'
            xmin = np.min(np.array(poly)[:, 0])
            ymin = np.min(np.array(poly)[:, 1])
            xmax = np.max(np.array(poly)[:, 0])
            ymax = np.max(np.array(poly)[:, 1])
            xmin,ymin,xmax,ymax= int(xmin),int(ymin),int(xmax),int(ymax)
            xml_file.write('    <object>\n')
            xml_file.write('        <name>'+str(gt_cls)+'</name>\n')
            xml_file.write('        <pose>Unspecified</pose>\n')
            xml_file.write('        <truncated>0</truncated>\n')
            xml_file.write('        <difficult>0</difficult>\n')
            xml_file.write('        <bndbox>\n')
            xml_file.write('            <xmin>'+str(xmin)+'</xmin>\n')
            xml_file.write('            <ymin>'+str(ymin)+'</ymin>\n')
            xml_file.write('            <xmax>'+str(xmax)+'</xmax>\n')
            xml_file.write('            <ymax>'+str(ymax)+'</ymax>\n')
            xml_file.write('        </bndbox>\n')
            xml_file.write('    </object>\n')
        xml_file.write('</annotation>')
        xml_file.close()
    print(f'{mode} xml save done!')


gen_main_train_txt()
gen_main_train_txt('valid')
gen_xml_label('train')
gen_xml_label('valid')

```

</details>

æ•°æ®å¤„ç†å®Œæˆåï¼Œè½¬æ¢ä¸ºVOCæ ¼å¼çš„å°ç« æ£€æµ‹æ•°æ®å­˜å‚¨åœ¨~/data/seal_VOCç›®å½•ä¸‹ï¼Œç›®å½•ç»„ç»‡ç»“æ„ä¸ºï¼š

```text linenums="1"
â”œâ”€â”€ Annotations/
â”œâ”€â”€ ImageSets/
â”‚Â Â  â””â”€â”€ Main/
â”‚Â Â      â”œâ”€â”€ train.txt
â”‚Â Â      â””â”€â”€ valid.txt
â”œâ”€â”€ JPEGImages/
â”œâ”€â”€ train.txt
â””â”€â”€ valid.txt
â””â”€â”€ label_list.txt
```

Annotationsä¸‹ä¸ºæ•°æ®çš„æ ‡ç­¾ï¼ŒJPEGImagesç›®å½•ä¸‹ä¸ºå›¾åƒæ–‡ä»¶ï¼Œlabel_list.txtä¸ºæ ‡æ³¨æ£€æµ‹æ¡†ç±»åˆ«æ ‡ç­¾æ–‡ä»¶ã€‚

åœ¨æ¥ä¸‹æ¥ä¸€èŠ‚ä¸­ï¼Œå°†ä»‹ç»å¦‚ä½•ä½¿ç”¨PaddleDetectionå·¥å…·åº“å®Œæˆå°ç« æ£€æµ‹æ¨¡å‹çš„è®­ç»ƒã€‚

## 4. å°ç« æ£€æµ‹å®è·µ

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå°ç« å¤šæ˜¯å‡ºç°åœ¨åˆåŒï¼Œå‘ç¥¨ï¼Œå…¬å‘Šç­‰åœºæ™¯ä¸­ï¼Œå°ç« æ–‡å­—è¯†åˆ«çš„ä»»åŠ¡éœ€è¦æ’é™¤å›¾åƒä¸­èƒŒæ™¯æ–‡å­—çš„å½±å“ï¼Œå› æ­¤éœ€è¦å…ˆæ£€æµ‹å‡ºå›¾åƒä¸­çš„å°ç« åŒºåŸŸã€‚

å€ŸåŠ©PaddleDetectionç›®æ ‡æ£€æµ‹åº“å¯ä»¥å¾ˆå®¹æ˜“çš„å®ç°å°ç« æ£€æµ‹ä»»åŠ¡ï¼Œä½¿ç”¨PaddleDetectionè®­ç»ƒå°ç« æ£€æµ‹ä»»åŠ¡æµç¨‹å¦‚ä¸‹ï¼š

- é€‰æ‹©ç®—æ³•
- ä¿®æ”¹æ•°æ®é›†é…ç½®è·¯å¾„
- å¯åŠ¨è®­ç»ƒ

**ç®—æ³•é€‰æ‹©**

PaddleDetectionä¸­æœ‰è®¸å¤šæ£€æµ‹ç®—æ³•å¯ä»¥é€‰æ‹©ï¼Œè€ƒè™‘åˆ°æ¯æ¡æ•°æ®ä¸­å°ç« åŒºåŸŸè¾ƒä¸ºæ¸…æ™°ï¼Œä¸”è€ƒè™‘åˆ°æ€§èƒ½éœ€æ±‚ã€‚åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨mobilenetv3ä¸ºbackboneçš„ppyoloç®—æ³•å®Œæˆå°ç« æ£€æµ‹ä»»åŠ¡ï¼Œå¯¹åº”çš„é…ç½®æ–‡ä»¶æ˜¯ï¼šconfigs/ppyolo/ppyolo_mbv3_large.yml

**ä¿®æ”¹é…ç½®æ–‡ä»¶**

é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ•°æ®è·¯å¾„æ˜¯COCOï¼Œ
éœ€è¦ä¿®æ”¹ä¸ºå°ç« æ£€æµ‹çš„æ•°æ®è·¯å¾„ï¼Œä¸»è¦ä¿®æ”¹å¦‚ä¸‹:
åœ¨é…ç½®æ–‡ä»¶'configs/ppyolo/ppyolo_mbv3_large.yml'æœ«å°¾å¢åŠ å¦‚ä¸‹å†…å®¹ï¼š

```yaml linenums="1"
metric: VOC
map_type: 11point
num_classes: 2

TrainDataset:
  !VOCDataSet
    dataset_dir: dataset/seal_VOC
    anno_path: train.txt
    label_list: label_list.txt
    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']

EvalDataset:
  !VOCDataSet
    dataset_dir: dataset/seal_VOC
    anno_path: test.txt
    label_list: label_list.txt
    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']

TestDataset:
  !ImageFolder
    anno_path: dataset/seal_VOC/label_list.txt
```

é…ç½®æ–‡ä»¶ä¸­è®¾ç½®çš„æ•°æ®è·¯å¾„åœ¨PaddleDetection/datasetç›®å½•ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†å¤„ç†åçš„å°ç« æ£€æµ‹è®­ç»ƒæ•°æ®ç§»åŠ¨åˆ°PaddleDetection/datasetç›®å½•ä¸‹æˆ–è€…åˆ›å»ºä¸€ä¸ªè½¯è¿æ¥ã€‚

```bash linenums="1"
!ln -s seal_VOC ./PaddleDetection/dataset/
```

å¦å¤–å›¾è±¡ä¸­å°ç« æ•°é‡æ¯”è¾ƒå°‘ï¼Œå¯ä»¥è°ƒæ•´NMSåå¤„ç†çš„æ£€æµ‹æ¡†æ•°é‡ï¼Œå³keep_top_kï¼Œnms_top_k ä»100ï¼Œ1000ï¼Œè°ƒæ•´ä¸º10ï¼Œ100ã€‚åœ¨é…ç½®æ–‡ä»¶'configs/ppyolo/ppyolo_mbv3_large.yml'æœ«å°¾å¢åŠ å¦‚ä¸‹å†…å®¹å®Œæˆåå¤„ç†å‚æ•°çš„è°ƒæ•´

```yaml linenums="1"
BBoxPostProcess:
  decode:
    name: YOLOBox
    conf_thresh: 0.005
    downsample_ratio: 32
    clip_bbox: true
    scale_x_y: 1.05
  nms:
    name: MultiClassNMS
    keep_top_k: 10  # ä¿®æ”¹å‰100
    nms_threshold: 0.45
    nms_top_k: 100  # ä¿®æ”¹å‰1000
    score_threshold: 0.005
```

ä¿®æ”¹å®Œæˆåï¼Œéœ€è¦åœ¨PaddleDetectionä¸­å¢åŠ å°ç« æ•°æ®çš„å¤„ç†ä»£ç ï¼Œå³åœ¨PaddleDetection/ppdet/data/source/ç›®å½•ä¸‹åˆ›å»ºseal.pyæ–‡ä»¶ï¼Œæ–‡ä»¶ä¸­å¡«å……å¦‚ä¸‹ä»£ç ï¼š

<details>

```python linenums="1"
import os
import numpy as np
from ppdet.core.workspace import register, serializable
from .dataset import DetDataset
import cv2
import json

from ppdet.utils.logger import setup_logger
logger = setup_logger(__name__)


@register
@serializable
class SealDataSet(DetDataset):
    """
    Load dataset with COCO format.

    Args:
        dataset_dir (str): root directory for dataset.
        image_dir (str): directory for images.
        anno_path (str): coco annotation file path.
        data_fields (list): key name of data dictionary, at least have 'image'.
        sample_num (int): number of samples to load, -1 means all.
        load_crowd (bool): whether to load crowded ground-truth.
            False as default
        allow_empty (bool): whether to load empty entry. False as default
        empty_ratio (float): the ratio of empty record number to total
            record's, if empty_ratio is out of [0. ,1.), do not sample the
            records and use all the empty entries. 1. as default
    """

    def __init__(self,
                 dataset_dir=None,
                 image_dir=None,
                 anno_path=None,
                 data_fields=['image'],
                 sample_num=-1,
                 load_crowd=False,
                 allow_empty=False,
                 empty_ratio=1.):
        super(SealDataSet, self).__init__(dataset_dir, image_dir, anno_path,
                                          data_fields, sample_num)
        self.load_image_only = False
        self.load_semantic = False
        self.load_crowd = load_crowd
        self.allow_empty = allow_empty
        self.empty_ratio = empty_ratio

    def _sample_empty(self, records, num):
        # if empty_ratio is out of [0. ,1.), do not sample the records
        if self.empty_ratio < 0. or self.empty_ratio >= 1.:
            return records
        import random
        sample_num = min(
            int(num * self.empty_ratio / (1 - self.empty_ratio)), len(records))
        records = random.sample(records, sample_num)
        return records

    def parse_dataset(self):
        anno_path = os.path.join(self.dataset_dir, self.anno_path)
        image_dir = os.path.join(self.dataset_dir, self.image_dir)

        records = []
        empty_records = []
        ct = 0

        assert anno_path.endswith('.txt'), \
            'invalid seal_gt file: ' + anno_path

        all_datas = open(anno_path, 'r').readlines()

        for idx, line in enumerate(all_datas):
            im_path, label = line.strip().split('\t')
            img_path = os.path.join(image_dir, im_path)
            label = json.loads(label)
            im_h, im_w, im_c = cv2.imread(img_path).shape

            coco_rec = {
                'im_file': img_path,
                'im_id': np.array([idx]),
                'h': im_h,
                'w': im_w,
            } if 'image' in self.data_fields else {}

            if not self.load_image_only:
                bboxes = []
                for anno in label:
                    poly = anno['polys']
                    # poly to box
                    x1 = np.min(np.array(poly)[:, 0])
                    y1 = np.min(np.array(poly)[:, 1])
                    x2 = np.max(np.array(poly)[:, 0])
                    y2 = np.max(np.array(poly)[:, 1])
                eps = 1e-5
                if x2 - x1 > eps and y2 - y1 > eps:
                    clean_box = [
                        round(float(x), 3) for x in [x1, y1, x2, y2]
                    ]
                    anno = {'clean_box': clean_box, 'gt_cls':int(anno['cls'])}
                    bboxes.append(anno)
                else:
                    logger.info("invalid box")

            num_bbox = len(bboxes)
            if num_bbox <= 0:
                continue

            gt_bbox = np.zeros((num_bbox, 4), dtype=np.float32)
            gt_class = np.zeros((num_bbox, 1), dtype=np.int32)
            is_crowd = np.zeros((num_bbox, 1), dtype=np.int32)
            # gt_poly = [None] * num_bbox

            for i, box in enumerate(bboxes):
                gt_class[i][0] = box['gt_cls']
                gt_bbox[i, :] = box['clean_box']
                is_crowd[i][0] = 0

            gt_rec = {
                        'is_crowd': is_crowd,
                        'gt_class': gt_class,
                        'gt_bbox': gt_bbox,
                        # 'gt_poly': gt_poly,
                    }

            for k, v in gt_rec.items():
                if k in self.data_fields:
                    coco_rec[k] = v

            records.append(coco_rec)
            ct += 1
            if self.sample_num > 0 and ct >= self.sample_num:
                break
        self.roidbs = records
```

</details>

**å¯åŠ¨è®­ç»ƒ**

å¯åŠ¨å•å¡è®­ç»ƒçš„å‘½ä»¤ä¸ºï¼š

```bash linenums="1"
!python3  tools/train.py  -c configs/ppyolo/ppyolo_mbv3_large.yml  --eval

# åˆ†å¸ƒå¼è®­ç»ƒå‘½ä»¤ä¸ºï¼š
!python3 -m paddle.distributed.launch   --gpus 0,1,2,3,4,5,6,7  tools/train.py  -c configs/ppyolo/ppyolo_mbv3_large.yml  --eval
```

è®­ç»ƒå®Œæˆåï¼Œæ—¥å¿—ä¸­ä¼šæ‰“å°æ¨¡å‹çš„ç²¾åº¦ï¼š

```bash linenums="1"
[07/05 11:42:09] ppdet.engine INFO: Eval iter: 0
[07/05 11:42:14] ppdet.metrics.metrics INFO: Accumulating evaluatation results...
[07/05 11:42:14] ppdet.metrics.metrics INFO: mAP(0.50, 11point) = 99.31%
[07/05 11:42:14] ppdet.engine INFO: Total sample number: 112, averge FPS: 26.45840794253432
[07/05 11:42:14] ppdet.engine INFO: Best test bbox ap is 0.996.
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è§‚å¯Ÿé¢„æµ‹ç»“æœï¼š

```bash linenums="1"
!python3 tools/infer.py -c configs/ppyolo/ppyolo_mbv3_large.yml -o weights=./output/ppyolo_mbv3_large/model_final.pdparams  --img_dir=./test.jpg
```

é¢„æµ‹ç»“æœå¦‚ä¸‹ï¼š

![](./images/0f650c032b0f4d56bd639713924768cc820635e9977845008d233f465291a29e.jpeg)

## 5. å°ç« æ–‡å­—è¯†åˆ«å®è·µ

åœ¨ä½¿ç”¨ppyoloæ£€æµ‹åˆ°å°ç« åŒºåŸŸåï¼Œæ¥ä¸‹æ¥å€ŸåŠ©PaddleOCRé‡Œçš„æ–‡å­—è¯†åˆ«èƒ½åŠ›ï¼Œå®Œæˆå°ç« ä¸­æ–‡å­—çš„è¯†åˆ«ã€‚

PaddleOCRä¸­çš„OCRç®—æ³•åŒ…å«æ–‡å­—æ£€æµ‹ç®—æ³•ï¼Œæ–‡å­—è¯†åˆ«ç®—æ³•ä»¥åŠOCRç«¯å¯¹ç«¯ç®—æ³•ã€‚

æ–‡å­—æ£€æµ‹ç®—æ³•è´Ÿè´£æ£€æµ‹åˆ°å›¾åƒä¸­çš„æ–‡å­—ï¼Œå†ç”±æ–‡å­—è¯†åˆ«æ¨¡å‹è¯†åˆ«å‡ºæ£€æµ‹åˆ°çš„æ–‡å­—ï¼Œè¿›è€Œå®ç°OCRçš„ä»»åŠ¡ã€‚æ–‡å­—æ£€æµ‹+æ–‡å­—è¯†åˆ«ä¸²è”å®ŒæˆOCRä»»åŠ¡çš„æ¶æ„ç§°ä¸ºä¸¤é˜¶æ®µçš„OCRç®—æ³•ã€‚ç›¸å¯¹åº”çš„ç«¯å¯¹ç«¯çš„OCRæ–¹æ³•å¯ä»¥ç”¨ä¸€ä¸ªç®—æ³•åŒæ—¶å®Œæˆæ–‡å­—æ£€æµ‹å’Œè¯†åˆ«çš„ä»»åŠ¡ã€‚

| æ–‡å­—æ£€æµ‹ | æ–‡å­—è¯†åˆ« | ç«¯å¯¹ç«¯ç®—æ³• |
| -------- | -------- | -------- |
| DB\DB++\EAST\SAST\PSENet     | SVTR\CRNN\NRTN\Abinet\SAR\...     | PGNet     |

æœ¬èŠ‚ä¸­å°†åˆ†åˆ«ä»‹ç»ç«¯å¯¹ç«¯çš„æ–‡å­—æ£€æµ‹è¯†åˆ«ç®—æ³•ä»¥åŠä¸¤é˜¶æ®µçš„æ–‡å­—æ£€æµ‹è¯†åˆ«ç®—æ³•åœ¨å°ç« æ£€æµ‹è¯†åˆ«ä»»åŠ¡ä¸Šçš„å®è·µã€‚

### 5.1 ç«¯å¯¹ç«¯å°ç« æ–‡å­—è¯†åˆ«å®è·µ

æœ¬èŠ‚ä»‹ç»ä½¿ç”¨PaddleOCRé‡Œçš„PGNetç®—æ³•å®Œæˆå°ç« æ–‡å­—è¯†åˆ«ã€‚

PGNetå±äºç«¯å¯¹ç«¯çš„æ–‡å­—æ£€æµ‹è¯†åˆ«ç®—æ³•ï¼Œåœ¨PaddleOCRä¸­çš„é…ç½®æ–‡ä»¶ä¸ºï¼š
[PaddleOCR/configs/e2e/e2e_r50_vd_pg.yml](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/configs/e2e/e2e_r50_vd_pg.yml)

ä½¿ç”¨PGNetå®Œæˆæ–‡å­—æ£€æµ‹è¯†åˆ«ä»»åŠ¡çš„æ­¥éª¤ä¸ºï¼š

- ä¿®æ”¹é…ç½®æ–‡ä»¶
- å¯åŠ¨è®­ç»ƒ

PGNeté»˜è®¤é…ç½®æ–‡ä»¶çš„æ•°æ®è·¯å¾„ä¸ºtotaltextæ•°æ®é›†è·¯å¾„ï¼Œæœ¬æ¬¡è®­ç»ƒä¸­ï¼Œéœ€è¦ä¿®æ”¹ä¸ºä¸Šä¸€èŠ‚æ•°æ®å¤„ç†åå¾—åˆ°çš„æ ‡ç­¾æ–‡ä»¶å’Œæ•°æ®ç›®å½•ï¼š

è®­ç»ƒæ•°æ®é…ç½®ä¿®æ”¹åå¦‚ä¸‹ï¼š

```yaml linenums="1"
Train:
  dataset:
    name: PGDataSet
    data_dir: ./train_data/seal_ppocr
    label_file_list: [./train_data/seal_ppocr/seal_ppocr_img.txt]
    ratio_list: [1.0]
```

æµ‹è¯•æ•°æ®é›†é…ç½®ä¿®æ”¹åå¦‚ä¸‹ï¼š

```yaml linenums="1"
Eval:
  dataset:
    name: PGDataSet
    data_dir: ./train_data/seal_ppocr_test
    label_file_list: [./train_data/seal_ppocr_test/seal_ppocr_img.txt]
```

å¯åŠ¨è®­ç»ƒçš„å‘½ä»¤ä¸º:

```bash linenums="1"
!python3 tools/train.py -c configs/e2e/e2e_r50_vd_pg.yml
```

æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥å¾—åˆ°æœ€ç»ˆçš„ç²¾åº¦ä¸º47.4%ã€‚æ•°æ®é‡è¾ƒå°‘ï¼Œä»¥åŠæ•°æ®è´¨é‡è¾ƒå·®ä¼šå½±å“æ¨¡å‹çš„è®­ç»ƒç²¾åº¦ï¼Œå¦‚æœæœ‰æ›´å¤šçš„æ•°æ®å‚ä¸è®­ç»ƒï¼Œç²¾åº¦å°†è¿›ä¸€æ­¥æå‡ã€‚

å¦‚éœ€è·å–å·²è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç‚¹å‡»æ–‡æœ«çš„é“¾æ¥ï¼ŒåŠ å…¥å®˜æ–¹äº¤æµç¾¤è·å–å…¨éƒ¨OCRå‚ç±»æ¨¡å‹ä¸‹è½½é“¾æ¥ã€ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ç­‰å…¨å¥—OCRå­¦ä¹ èµ„æ–™ğŸ

### 5.2 ä¸¤é˜¶æ®µå°ç« æ–‡å­—è¯†åˆ«å®è·µ

ä¸Šä¸€èŠ‚ä»‹ç»äº†ä½¿ç”¨PGNetå®ç°å°ç« è¯†åˆ«ä»»åŠ¡çš„è®­ç»ƒæµç¨‹ã€‚æœ¬å°èŠ‚å°†ä»‹ç»ä½¿ç”¨PaddleOCRé‡Œçš„æ–‡å­—æ£€æµ‹å’Œæ–‡å­—è¯†åˆ«ç®—æ³•åˆ†åˆ«å®Œæˆå°ç« æ–‡å­—çš„æ£€æµ‹å’Œè¯†åˆ«ã€‚

#### 5.2.1 å°ç« æ–‡å­—æ£€æµ‹

PaddleOCRä¸­åŒ…å«ä¸°å¯Œçš„æ–‡å­—æ£€æµ‹ç®—æ³•ï¼ŒåŒ…å«DBï¼ŒDB++ï¼ŒEASTï¼ŒSASTï¼ŒPSENetç­‰ç­‰ã€‚å…¶ä¸­DBï¼ŒDB++ï¼ŒPSENetå‡æ”¯æŒå¼¯æ›²æ–‡å­—æ£€æµ‹ï¼Œæœ¬é¡¹ç›®ä¸­ï¼Œä½¿ç”¨DB++ä½œä¸ºå°ç« å¼¯æ›²æ–‡å­—æ£€æµ‹ç®—æ³•ã€‚

PaddleOCRä¸­å‘å¸ƒçš„db++æ–‡å­—æ£€æµ‹ç®—æ³•æ¨¡å‹æ˜¯è‹±æ–‡æ–‡æœ¬æ£€æµ‹æ¨¡å‹ï¼Œå› æ­¤éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

ä¿®æ”¹[DB++é…ç½®æ–‡ä»¶](DB++çš„é»˜è®¤é…ç½®æ–‡ä»¶ä½äº[configs/det/det_r50_db++_icdar15.yml](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/configs/det/det_r50_db%2B%2B_icdar15.yml)
ä¸­çš„æ•°æ®è·¯å¾„ï¼š

```yaml linenums="1"
Train:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/seal_ppocr
    label_file_list: [./train_data/seal_ppocr/seal_ppocr_img.txt]
    ratio_list: [1.0]
```

æµ‹è¯•æ•°æ®é›†é…ç½®ä¿®æ”¹åå¦‚ä¸‹ï¼š

```yaml linenums="1"
Eval:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/seal_ppocr_test
    label_file_list: [./train_data/seal_ppocr_test/seal_ppocr_img.txt]
```

å¯åŠ¨è®­ç»ƒï¼š

```bash linenums="1"
!python3 tools/train.py  -c  configs/det/det_r50_db++_icdar15.yml -o Global.epoch_num=100
```

è€ƒè™‘åˆ°æ•°æ®è¾ƒå°‘ï¼Œé€šè¿‡Global.epoch_numè®¾ç½®ä»…è®­ç»ƒ100ä¸ªepochã€‚
æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œåœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹çš„å¯è§†åŒ–æ•ˆæœå¦‚ä¸‹ï¼š

![](./images/498119182f0a414ab86ae2de752fa31c9ddc3a74a76847049cc57884602cb269-20240704185744623.png)

å¦‚éœ€è·å–å·²è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç‚¹å‡»æ–‡æœ«çš„é“¾æ¥ï¼ŒåŠ å…¥å®˜æ–¹äº¤æµç¾¤è·å–å…¨éƒ¨OCRå‚ç±»æ¨¡å‹ä¸‹è½½é“¾æ¥ã€ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ç­‰å…¨å¥—OCRå­¦ä¹ èµ„æ–™ğŸ

#### 5.2.2 å°ç« æ–‡å­—è¯†åˆ«

ä¸Šä¸€èŠ‚ä¸­å®Œæˆäº†å°ç« æ–‡å­—çš„æ£€æµ‹æ¨¡å‹è®­ç»ƒï¼Œæœ¬èŠ‚ä»‹ç»å°ç« æ–‡å­—è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒã€‚è¯†åˆ«æ¨¡å‹é‡‡ç”¨SVTRç®—æ³•ï¼ŒSVTRç®—æ³•æ˜¯IJCAIæ”¶å½•çš„æ–‡å­—è¯†åˆ«ç®—æ³•ï¼ŒSVTRæ¨¡å‹å…·å¤‡è¶…è½»é‡é«˜ç²¾åº¦çš„ç‰¹ç‚¹ã€‚

åœ¨å¯åŠ¨è®­ç»ƒä¹‹å‰ï¼Œéœ€è¦å‡†å¤‡å°ç« æ–‡å­—è¯†åˆ«éœ€è¦çš„æ•°æ®é›†ï¼Œéœ€è¦ä½¿ç”¨å¦‚ä¸‹ä»£ç ï¼Œå°†å°ç« ä¸­çš„æ–‡å­—åŒºåŸŸå‰ªåˆ‡å‡ºæ¥æ„å»ºè®­ç»ƒé›†ã€‚

```python linenums="1"
import cv2
import numpy as np

def get_rotate_crop_image(img, points):
    '''
    img_height, img_width = img.shape[0:2]
    left = int(np.min(points[:, 0]))
    right = int(np.max(points[:, 0]))
    top = int(np.min(points[:, 1]))
    bottom = int(np.max(points[:, 1]))
    img_crop = img[top:bottom, left:right, :].copy()
    points[:, 0] = points[:, 0] - left
    points[:, 1] = points[:, 1] - top
    '''
    assert len(points) == 4, "shape of points must be 4*2"
    img_crop_width = int(
        max(
            np.linalg.norm(points[0] - points[1]),
            np.linalg.norm(points[2] - points[3])))
    img_crop_height = int(
        max(
            np.linalg.norm(points[0] - points[3]),
            np.linalg.norm(points[1] - points[2])))
    pts_std = np.float32([[0, 0], [img_crop_width, 0],
                          [img_crop_width, img_crop_height],
                          [0, img_crop_height]])
    M = cv2.getPerspectiveTransform(points, pts_std)
    dst_img = cv2.warpPerspective(
        img,
        M, (img_crop_width, img_crop_height),
        borderMode=cv2.BORDER_REPLICATE,
        flags=cv2.INTER_CUBIC)
    dst_img_height, dst_img_width = dst_img.shape[0:2]
    if dst_img_height * 1.0 / dst_img_width >= 1.5:
        dst_img = np.rot90(dst_img)
    return dst_img


def run(data_dir, label_file, save_dir):
    datas = open(label_file, 'r').readlines()
    for idx, line in enumerate(datas):
        img_path, label = line.strip().split('\t')
        img_path = os.path.join(data_dir, img_path)

        label = json.loads(label)
        src_im = cv2.imread(img_path)
        if src_im is None:
            continue

        for anno in label:
            seal_box = anno['seal_box']
            txt_boxes = anno['polys']
            crop_im = get_rotate_crop_image(src_im, text_boxes)

            save_path = os.path.join(save_dir, f'{idx}.png')
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            # print(src_im.shape)
            cv2.imwrite(save_path, crop_im)

```

æ•°æ®å¤„ç†å®Œæˆåï¼Œå³å¯é…ç½®è®­ç»ƒçš„é…ç½®æ–‡ä»¶ã€‚SVTRé…ç½®æ–‡ä»¶é€‰æ‹©[configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml)
ä¿®æ”¹SVTRé…ç½®æ–‡ä»¶ä¸­çš„è®­ç»ƒæ•°æ®éƒ¨åˆ†å¦‚ä¸‹ï¼š

```yaml linenums="1"
Train:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/seal_ppocr_crop/
    label_file_list:
    - ./train_data/seal_ppocr_crop/train_list.txt
```

ä¿®æ”¹é¢„æµ‹éƒ¨åˆ†é…ç½®æ–‡ä»¶ï¼š

```yaml linenums="1"
Train:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/seal_ppocr_crop/
    label_file_list:
    - ./train_data/seal_ppocr_crop_test/train_list.txt
```

å¯åŠ¨è®­ç»ƒï¼š

```bash linenums="1"
!python3 tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml

```

è®­ç»ƒå®Œæˆåå¯ä»¥å‘ç°æµ‹è¯•é›†æŒ‡æ ‡è¾¾åˆ°äº†61%ã€‚
ç”±äºæ•°æ®è¾ƒå°‘ï¼Œè®­ç»ƒæ—¶ä¼šå‘ç°åœ¨è®­ç»ƒé›†ä¸Šçš„accæŒ‡æ ‡è¿œå¤§äºæµ‹è¯•é›†ä¸Šçš„accæŒ‡æ ‡ï¼Œå³å‡ºç°è¿‡æ‹Ÿåˆç°è±¡ã€‚é€šè¿‡è¡¥å……æ•°æ®å’Œä¸€äº›æ•°æ®å¢å¼ºå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚
