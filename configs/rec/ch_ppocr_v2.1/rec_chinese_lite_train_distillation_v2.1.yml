Global:
  debug: false
  use_gpu: true
  epoch_num: 800
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_chinese_lite_distillation_v2.1
  save_epoch_step: 3
  eval_batch_step: [0, 2000]
  cal_metric_during_train: true
  pretrained_model:
  checkpoints:
  save_inference_dir:
  use_visualdl: false
  infer_img: doc/imgs_words/ch/word_1.jpg
  character_dict_path: ppocr/utils/ppocr_keys_v1.txt
  character_type: ch
  max_text_length: 25
  infer_mode: false
  use_space_char: false
  distributed: true
  save_res_path: ./output/rec/predicts_chinese_lite_distillation_v2.1.txt


Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  lr:
    name: Cosine
    learning_rate: 0.0005
    warmup_epoch: 5
  regularizer:
    name: L2
    factor: 1.0e-05
Architecture:
  name: DistillationModel
  algorithm: Distillation
  Models:
    Student:
      pretrained:
      freeze_params: false
      return_all_feats: true
      model_type: rec
      algorithm: CRNN
      Transform:
      Backbone:
        name: MobileNetV3
        scale: 0.5
        model_name: small
        small_stride: [1, 2, 2, 2]
      Neck:
        name: SequenceEncoder
        encoder_type: rnn
        hidden_size: 48
      Head:
        name: CTCHead
        fc_decay: 0.00001
    Teacher:
      pretrained:
      freeze_params: false
      return_all_feats: true
      model_type: rec
      algorithm: CRNN
      Transform:
      Backbone:
        name: MobileNetV3
        scale: 0.5
        model_name: small
        small_stride: [1, 2, 2, 2]
      Neck:
        name: SequenceEncoder
        encoder_type: rnn
        hidden_size: 48
      Head:
        name: CTCHead
        fc_decay: 0.00001
  

Loss:
  name: CombinedLoss
  loss_config_list:
  - DistillationCTCLoss:
      weight: 1.0
      model_name_list: ["Student", "Teacher"]
      key: head_out
  - DistillationDMLLoss:
      weight: 1.0
      act: "softmax"
      model_name_pairs:
      - ["Student", "Teacher"]
      key: head_out
  - DistillationDistanceLoss:
      weight: 1.0
      mode: "l2"
      model_name_pairs:
      - ["Student", "Teacher"]
      key: backbone_out

PostProcess:
  name: DistillationCTCLabelDecode
  model_name: ["Student", "Teacher"]
  key: head_out

Metric:
  name: DistillationMetric
  base_metric_name: RecMetric
  main_indicator: acc
  key: "Student"

Train:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/
    label_file_list:
    - ./train_data/train_list.txt
    transforms:
    - DecodeImage:
        img_mode: BGR
        channel_first: false
    - RecAug:
    - CTCLabelEncode:
    - RecResizeImg:
        image_shape: [3, 32, 320]
    - KeepKeys:
        keep_keys:
        - image
        - label
        - length
  loader:
    shuffle: true
    batch_size_per_card: 128
    drop_last: true
    num_sections: 1
    num_workers: 8
Eval:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data
    label_file_list:
    - ./train_data/val_list.txt
    transforms:
    - DecodeImage:
        img_mode: BGR
        channel_first: false
    - CTCLabelEncode:
    - RecResizeImg:
        image_shape: [3, 32, 320]
    - KeepKeys:
        keep_keys:
        - image
        - label
        - length
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 128
    num_workers: 8
