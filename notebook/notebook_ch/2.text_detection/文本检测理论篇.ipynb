{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# OCR七日课之文本检测综述\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 文本检测\n",
    "\n",
    "文本检测任务是找出图像或视频中的文字位置。不同于目标检测任务，目标检测不仅要解决定位问题，还要解决目标分类问题。\n",
    "\n",
    "文本在图像中的表现形式可以视为一种‘目标‘，通用的目标检测的方法也适用于文本检测，从任务本身上来看：\n",
    "\n",
    "- 目标检测：给定图像或者视频，找出目标的位置（box），并给出目标的类别；\n",
    "- 文本检测：给定输入图像或者视频，找出文本的区域，可以是单字符位置或者整个文本行位置；\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/af2d8eca913a4d5a968945ae6cac180b009c6cc94abc43bfbaf1ba6a3de98125\" width=\"400\" ></center>\n",
    "\n",
    "<br><center>图1 目标检测示意图</center>\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/400b9100573b4286b40b0a668358bcab9627f169ab934133a1280361505ddd33\" width=\"1000\" ></center>\n",
    "\n",
    "<br><center>图2 文本检测示意图</center>\n",
    "\n",
    "目标检测和文本检测同属于“定位”问题。但是文本检测无需对目标分类，并且文本形状复杂多样。\n",
    "\n",
    "当前所说的文本检测一般是自然场景文本检测，其难点在于：\n",
    "\n",
    "1. 自然场景中文本具有多样性：文本检测受到文字颜色、大小、字体、形状、方向、语言、以及文本长度的影响；\n",
    "2. 复杂的背景和干扰；文本检测受到图像失真，模糊，低分辨率，阴影，亮度等因素的影响；\n",
    "3. 文本密集甚至重叠会影响文字的检测；\n",
    "4. 文字存在局部一致性，文本行的一小部分，也可视为是独立的文本；\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/072f208f2aff47e886cf2cf1378e23c648356686cf1349c799b42f662d8ced00\"\n",
    "width=\"1000\" ></center>\n",
    "\n",
    "<br><center>图3 文本检测场景</center>\n",
    "\n",
    "针对以上问题，衍生了很多基于深度学习的文本检测算法，解决自然场景文字检测问题，这些方法可以分为基于回归和基于分割的文本检测方法。\n",
    "\n",
    "下一节将简要介绍基于深度学习技术的经典文字检测算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 文本检测方法介绍\n",
    "\n",
    "\n",
    "近些年来基于深度学习的文本检测算法层出不穷，这些方法大致可以分为两类：\n",
    "1. 基于回归的文本检测方法\n",
    "2. 基于分割的文本检测方法\n",
    "\n",
    "\n",
    "本节筛选了2017-2021年的常用文本检测方法，按照如上两类方法分类如下表格所示：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/22314238b70b486f942701107ffddca48b87235a473c4d8db05b317f132daea0\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图4 文本检测算法</center>\n",
    "\n",
    "\n",
    "### 2.1 基于回归的文本检测\n",
    "\n",
    "基于回归文本检测方法和目标检测算法的方法相似，文本检测方法只有两个类别，图像中的文本视为待检测的目标，其余部分视为背景。\n",
    "\n",
    "#### 2.1.1 水平文本检测\n",
    "\n",
    "早期基于深度学习的文本检测算法是从目标检测的方法改进而来，支持水平文本检测。比如TextBoxes算法基于SSD算法改进而来，CTPN根据二阶段目标检测Fast-RCNN算法改进而来。\n",
    "\n",
    "在TextBoxes[1]算法根据一阶段目标检测器SSD调整，将默认文本框更改为适应文本方向和宽高比的规格的四边形，提供了一种端对端训练的文字检测方法，并且无需复杂的后处理。\n",
    "- 采用更大长宽比的预选框\n",
    "- 卷积核从3x3变成了1x5，更适合长文本检测\n",
    "- 采用多尺度输入\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/3864ccf9d009467cbc04225daef0eb562ac0c8c36f9b4f5eab036c319e5f05e7\" width=\"1000\" ></center>\n",
    "<br><center>图5 textbox框架图</center>\n",
    "\n",
    "CTPN[3]基于Fast-RCNN算法，扩展RPN模块并且设计了基于CRNN的模块让整个网络从卷积特征中检测到文本序列，二阶段的方法通过ROI Pooling获得了更准确的特征定位。但是TextBoxes和CTPN只支持检测横向文本。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/452833c2016e4cf7b35291efd09740c13c4bfb8f7c56446b8f7a02fc7eb3e901\" width=\"1000\" ></center>\n",
    "<br><center>图6 CTPN框架图</center>\n",
    "\n",
    "#### 2.1.2 任意角度文本检测\n",
    "\n",
    "TextBoxes++[2]在TextBoxes基础上进行改进，支持检测任意角度的文本。从结构上来说，不同于TextBoxes，TextBoxes++针对多角度文本进行检测，首先修改预选框的宽高比，调整宽高比aspect ratio为1、2、3、5、1/2、1/3、1/5。其次是将$1*5$的卷积核改为$3*5$，更好的学习倾斜文本的特征；最后，TextBoxes++的输出旋转框的表示信息。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/ae96e3acbac04be296b6d54a4d72e5881d592fcc91f44882b24bc7d38b9d2658\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图7 TextBoxes++框架图</center>\n",
    "\n",
    "\n",
    "EAST[4]针对倾斜文本的定位问题，提出了two-stage的文本检测方法，包含 FCN特征提取和NMS部分。EAST提出了一种新的文本检测pipline结构，可以端对端训练并且支持检测任意朝向的文本，并且具有结构简单，性能高的特点。FCN支持输出倾斜的矩形框和水平框，可以自由选择输出格式。\n",
    "- 如果输出检测形状为RBox，则输出Box旋转角度以及AABB文本形状信息，AABB表示到文本框上下左右边的偏移。RBox可以旋转矩形的文本。\n",
    "- 如果输出检测框为四点框，则输出的最后一个维度为8个数字，表示从四边形的四个角顶点的位置偏移。该输出方式可以预测不规则四边形的文本。\n",
    "\n",
    "考虑到FCN输出的文本框是比较冗余的，比如一个文本区域的邻近的像素生成的框重合度较高，但不是同一个文本生成的检测框，重合度都很小，因此EAST提出先按行合并预测框，最后再把剩下的四边形用原始的NMS筛选。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/d7411ada08714adab73fa0edf7555a679327b71e29184446a33d81cdd910e4fc\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图8 EAST框架图</center>           \n",
    "\n",
    "\n",
    "MOST[15]提出TFAM模块动态的调整粗粒度的检测结果的感受野，另外提出PA-NMS根据位置信息合并可靠的检测预测结果。此外，训练中还提出 Instance-wise IoU 损失函数，用于平衡训练，以处理不同尺度的文本实例。该方法可以和EAST方法结合，在检测极端长宽比和不同尺度的文本有更好的检测效果和性能。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/73052d9439714bba86ffe4a959d58c523b07baf3f1d74882b4517e71f5a645fe\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图9 MOST框架图</center>\n",
    "\n",
    "\n",
    "#### 2.1.3 弯曲文本检测\n",
    "\n",
    "利用回归的方法解决弯曲文本的检测问题，一个简单的思路是用多点坐标描述弯曲文本的边界多边形，然后直接预测多边形的顶点坐标。\n",
    "\n",
    "CTD[6]提出了直接预测弯曲文本14个顶点的边界多边形，网络中利用Bi-LSTM[13]层以细化顶点的预测坐标，实现了基于回归方法的弯曲文本检测。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/6e33d76ebb814cac9ebb2942b779054af160857125294cd69481680aca2fa98a\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图10 CTD框架图</center>\n",
    "\n",
    "\n",
    "\n",
    "LOMO[19]针对长文本和弯曲文本问题，提出迭代的优化文本定位特征获取更精细的文本定位，该方法包括三个部分，坐标回归模块DR，迭代优化模块IRM以及任意形状表达模块SEM。分别用于生成文本大致区域，迭代优化文本定位特征，预测文本区域、文本中心线以及文本边界。迭代的优化文本特征可以更好的解决长文本定位问题以及获得更精确的文本区域定位。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/e90adf3ca25a45a0af0b84a181fbe2c4954be1fcca8f4049957128548b7131ef\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图11 LOMO框架图</center>\n",
    "\n",
    "\n",
    "Contournet[18]基于提出对文本轮廓点建模获取弯曲文本检测框，该方法首先使用Adaptive-RPN获取文本区域的proposal特征，然后设计了局部正交纹理感知LOTM模块学习水平与竖直方向的纹理特征，并用轮廓点表示，最后，通过同时考虑两个正交方向上的特征响应，利用Point Re-Scoring算法可以有效地滤除强单向或弱正交激活的预测，最终文本轮廓可以用一组高质量的轮廓点表示出来。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/1f59ab5db899412f8c70ba71e8dd31d4ea9480d6511f498ea492c97dd2152384\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图12 Contournet框架图</center>\n",
    "\n",
    "\n",
    "PCR[14]提出渐进式的坐标回归处理弯曲文本检测问题，总体分为三个阶段，首先大致检测到文本区域，获得文本框，另外通过所设计的Contour Localization Mechanism预测文本最小包围框的角点坐标，然后通过叠加多个CLM模块和RCLM模块预测得到弯曲文本。该方法利用文本轮廓信息聚合得到丰富的文本轮廓特征表示，不仅能抑制冗余的噪声点对坐标回归的影响，还能更精确的定位文本区域。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/c677c4602cee44999ae4b38bd780b69795887f2ae10747968bb084db6209b6cc\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图13 PCR框架图</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### 2.2 基于分割的文本检测\n",
    "\n",
    "基于回归的方法虽然在文本检测上取得了很好的效果，但是对解决弯曲文本往往难以得到平滑的文本包围曲线，并且模型较为复杂不具备性能优势。于是研究者们提出了基于图像分割的文本分割方法，先从像素层面做分类，判别每一个像素点是否属于一个文本目标，得到文本区域的概率图，通过后处理方式得到文本分割区域的包围曲线。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/fb9e50c410984c339481869ba11c1f39f80a4d74920b44b084601f2f8a23099f\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图14 文本分割算法示意图</center>\n",
    "\n",
    "\n",
    "此类方法通常是基于分割的方法实现文本检测，基于分割的方法对不规则形状的文本检测有着天然的优势。基于分割的文本检测方法主体思想为，通过分割方法得到图像中文本区域，再利用opencv，polygon等后处理得到文本区域的最小包围曲线。\n",
    "\n",
    "\n",
    "Pixellink[7]采用分割的方法解决文本检测问题，分割对象为文本区域，将同属于一个文本行（单词）中的像素链接在一起来分割文本，直接从分割结果中提取文本边界框，无需位置回归就能达到基于回归的文本检测的效果。但是基于分割的方法存在一个问题，对于位置相近的文本，文本分割区域容易出现“粘连“问题。Wu, Yue等人[8]提出分割文本的同时，学习文本的边界位置，用于更好的区分文本区域。另外Tian等人[9]提出将同一文本的像素映射到映射空间，在映射空间中令统一文本的映射向量距离相近，不同文本的映射向量距离变远。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/462b5e1472824452a2c530939cda5e59ada226b2d0b745d19dd56068753a7f97\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图15 PixelLink框架图</center>\n",
    "\n",
    "MSR[20]针对文本检测的多尺度问题，提出提取相同图像的多个scale的特征，然后将这些特征融合并上采样到原图尺寸，网络最后预测文本中心区域、文本中心区域每个点到最近的边界点的x坐标偏移和y坐标偏移，最终可以得到文本区域的轮廓坐标集合。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/9597efd68a224d60b74d7c51c99f7ff0ba9939e5cdb84fb79209b7e213f7d039\"\n",
    "width=\"600\" ></center>\n",
    "<br><center>图16 MSR框架图</center>\n",
    "  \n",
    "针对基于分割的文本算法难以区分相邻文本的问题，PSENet[10]提出渐进式的尺度扩张网络学习文本分割区域，预测不同收缩比例的文本区域，并逐个扩大检测到的文本区域，该方法本质上是边界学习方法的变体，可以有效解决任意形状相邻文本的检测问题。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/fa870b69a2a5423cad7422f64c32e0645dfc31a4ecc94a52832cf8742cded5ba\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图17 PSENet框架图</center>\n",
    "\n",
    "假设PSENet后处理用了3个不同尺度的kernel，如上图s1,s2,s3所示。首先，从最小kernel s1开始，计算文本分割区域的连通域，得到(b)，然后，对连通域沿着上下左右做尺度扩张，对于扩张区域属于s2但不属于s1的像素，进行归类，遇到冲突点时，采用“先到先得”原则，重复尺度扩张的操作，最终可以得到不同文本行的独立的分割区域。\n",
    "\n",
    "\n",
    "Seglink++[17]针对弯曲文本和密集文本问题，提出了一种文本块单元之间的吸引关系和排斥关系的表征，然后设计了一种最小生成树算法进行单元组合得到最终的文本检测框，并提出instance-aware 损失函数使Seglink++方法可以端对端训练。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/1a16568361c0468db537ac25882eed096bca83f9c1544a92aee5239890f9d8d9\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图18 Seglink++框架图</center>\n",
    "\n",
    "虽然分割方法解决了弯曲文本的检测问题，但是复杂的后处理逻辑以及预测速度也是需要优化的目标。\n",
    "\n",
    "PAN[11]针对文本检测预测速度慢的问题，从网络设计和后处理方面进行改进，提升算法性能。首先，PAN使用了轻量级的ResNet18作为Backbone，另外设计了轻量级的特征增强模块FPEM和特征融合模块FFM增强Backbone提取的特征。在后处理方面，采用像素聚类方法，沿着预测的文本中心（kernel）四周合并与kernel的距离小于阈值d的像素。PAN保证高精度的同时具有更快的预测速度。\n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/a76771f91db246ee8be062f96fa2a8abc7598dd87e6d4755b63fac71a4ebc170\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图19 PAN框架图</center>\n",
    "\n",
    "DBNet[12]针对基于分割的方法需要使用阈值进行二值化处理而导致后处理耗时的问题，提出了可学习阈值并巧妙地设计了一个近似于阶跃函数的二值化函数，使得分割网络在训练的时候能端对端的学习文本分割的阈值。自动调节阈值不仅带来精度的提升，同时简化了后处理，提高了文本检测的性能。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/0d6423e3c79448f8b09090cf2dcf9d0c7baa0f6856c645808502678ae88d2917\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图20 DB框架图</center>\n",
    "\n",
    "FCENet[16]提出将文本包围曲线用傅立叶变换的参数表示，由于傅里叶系数表示在理论上可以拟合任意的封闭曲线，通过设计合适的模型预测基于傅里叶变换的任意形状文本包围框表示，从而实现了自然场景文本检测中对于高度弯曲文本实例的检测精度的提升。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/45e9a374d97145689a961977f896c8f9f470a66655234c1498e1c8477e277954\"\n",
    "width=\"1000\" ></center>\n",
    "<br><center>图21 FCENet框架图</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 总结\n",
    "\n",
    "本节介绍了近几年来文本检测领域的发展，包括基于回归、分割的文本检测方法，并分别列举并介绍了一些经典论文的方法思路。下一节以PaddleOCR开源库为例，详细介绍DBNet的算法原理以及核心代码实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 参考文献\n",
    "1. Liao, Minghui, et al. \"Textboxes: A fast text detector with a single deep neural network.\" Thirty-first AAAI conference on artificial intelligence. 2017.\n",
    "2. Liao, Minghui, Baoguang Shi, and Xiang Bai. \"Textboxes++: A single-shot oriented scene text detector.\" IEEE transactions on image processing 27.8 (2018): 3676-3690.\n",
    "3. Tian, Zhi, et al. \"Detecting text in natural image with connectionist text proposal network.\" European conference on computer vision. Springer, Cham, 2016.\n",
    "4. Zhou, Xinyu, et al. \"East: an efficient and accurate scene text detector.\" Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2017.\n",
    "5. Wang, Fangfang, et al. \"Geometry-aware scene text detection with instance transformation network.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.\n",
    "6. Yuliang, Liu, et al. \"Detecting curve text in the wild: New dataset and new solution.\" arXiv preprint arXiv:1712.02170 (2017).\n",
    "7. Deng, Dan, et al. \"Pixellink: Detecting scene text via instance segmentation.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 32. No. 1. 2018.\n",
    "8. Wu, Yue, and Prem Natarajan. \"Self-organized text detection with minimal post-processing via border learning.\" Proceedings of the IEEE International Conference on Computer Vision. 2017.\n",
    "9. Tian, Zhuotao, et al. \"Learning shape-aware embedding for scene text detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "10. Wang, Wenhai, et al. \"Shape robust text detection with progressive scale expansion network.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "11. Wang, Wenhai, et al. \"Efficient and accurate arbitrary-shaped text detection with pixel aggregation network.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.\n",
    "12. Liao, Minghui, et al. \"Real-time scene text detection with differentiable binarization.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 07. 2020.\n",
    "13. Hochreiter, Sepp, and Jürgen Schmidhuber. \"Long short-term memory.\" Neural computation 9.8 (1997): 1735-1780.\n",
    "14. Dai, Pengwen, et al. \"Progressive Contour Regression for Arbitrary-Shape Scene Text Detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n",
    "15. He, Minghang, et al. \"MOST: A Multi-Oriented Scene Text Detector with Localization Refinement.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n",
    "16. Zhu, Yiqin, et al. \"Fourier contour embedding for arbitrary-shaped text detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n",
    "17. Tang, Jun, et al. \"Seglink++: Detecting dense and arbitrary-shaped scene text by instance-aware component grouping.\" Pattern recognition 96 (2019): 106954.\n",
    "18. Wang, Yuxin, et al. \"Contournet: Taking a further step toward accurate arbitrary-shaped scene text detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n",
    "19. Zhang, Chengquan, et al. \"Look more than once: An accurate detector for text of arbitrary shapes.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "20. Xue C, Lu S, Zhang W. Msr: Multi-scale shape regression for scene text detection[J]. arXiv preprint arXiv:1901.02596, 2019. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
