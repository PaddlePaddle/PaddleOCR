"""
PaddleOCR MCP Server
é‡‡ç”¨FastMCP v2
"""

import base64
import io
import json
import os
import re
import sys
from contextlib import contextmanager
from io import StringIO
from typing import Optional, Union, Dict, Any

import numpy as np
from PIL import Image
from fastmcp import Context

# æœ¬åœ°OCRåº“ï¼ˆå¯é€‰å¯¼å…¥ï¼‰
try:
    from paddleocr import PaddleOCR, PPStructureV3
    LOCAL_OCR_AVAILABLE = True
except ImportError:
    LOCAL_OCR_AVAILABLE = False

# å…¨å±€å¼•æ“å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_ocr_engine = None
_structure_engine = None
_api_config = None


# ==================== é…ç½®ç®¡ç† ====================

def configure_api(api_url: str, api_token: str = None, timeout: int = 30):
    """é…ç½®APIå‚æ•° - æ”¯æŒAI Studioå’Œæœ¬åœ°æœåŠ¡"""
    global _api_config
    
    # æ™ºèƒ½æ£€æµ‹æœåŠ¡ç±»å‹
    is_local_service = any(indicator in api_url.lower() for indicator in [
        'localhost', '127.0.0.1', '10.', '192.168.', '172.'
    ])
    
    _api_config = {
        'url': api_url,
        'token': api_token,
        'timeout': timeout,
        'is_local_service': is_local_service,
        'service_type': 'layout-parsing' if 'layout-parsing' in api_url.lower() else 'ocr'
    }


def is_api_mode() -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºAPIæ¨¡å¼"""
    return _api_config is not None


# ==================== è¾“å…¥å¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼‰ ====================

def process_input(input_path: str) -> Union[str, np.ndarray]:
    """æ™ºèƒ½è¾“å…¥å¤„ç† - æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹å¼"""
    
    if is_api_mode():
        # APIæ¨¡å¼ï¼šè½¬æ¢ä¸ºBase64
        return _to_base64(input_path)
    else:
        # æœ¬åœ°æ¨¡å¼ï¼šä¼˜å…ˆæ–‡ä»¶è·¯å¾„
        if _is_file_path(input_path):
            return input_path
        elif input_path.startswith(('http://', 'https://')):
            return input_path
        elif _is_base64_like(input_path):
            return _base64_to_numpy(input_path)
        return input_path


async def process_input_async(input_path: str, ctx: Optional[Context] = None) -> Union[str, np.ndarray]:
    """å¼‚æ­¥æ™ºèƒ½è¾“å…¥å¤„ç† - æ”¯æŒURLä¸‹è½½"""
    
    if is_api_mode():
        # APIæ¨¡å¼ï¼šè½¬æ¢ä¸ºBase64
        return await _to_base64_async(input_path, ctx)
    else:
        # æœ¬åœ°æ¨¡å¼ï¼šä¼˜å…ˆæ–‡ä»¶è·¯å¾„
        if _is_file_path(input_path):
            return input_path
        elif input_path.startswith(('http://', 'https://')):
            return input_path
        elif _is_base64_like(input_path):
            return _base64_to_numpy(input_path)
        return input_path


def _to_base64(input_path: str) -> str:
    """è½¬æ¢ä»»ä½•è¾“å…¥ä¸ºBase64ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    # Data URI
    if input_path.startswith('data:'):
        return input_path.split(',', 1)[1] if ',' in input_path else input_path
    
    # å·²ç»æ˜¯Base64
    if _is_base64_like(input_path) and not _is_file_path(input_path):
        return input_path
    
    # æ–‡ä»¶è·¯å¾„
    if _is_file_path(input_path):
        with open(input_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')
    
    # URLéœ€è¦å¼‚æ­¥å¤„ç†ï¼Œè¿™é‡ŒæŠ›å‡ºå¼‚å¸¸æç¤º
    if input_path.startswith(('http://', 'https://')):
        raise ValueError("URL input requires async processing. Use process_input_async instead.")
    
    # é»˜è®¤å½“ä½œBase64
    return input_path


async def _to_base64_async(input_path: str, ctx: Optional[Context] = None) -> str:
    """è½¬æ¢ä»»ä½•è¾“å…¥ä¸ºBase64ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒURLä¸‹è½½ï¼‰"""
    # Data URI
    if input_path.startswith('data:'):
        return input_path.split(',', 1)[1] if ',' in input_path else input_path
    
    # å·²ç»æ˜¯Base64
    if _is_base64_like(input_path) and not _is_file_path(input_path):
        return input_path
    
    # URLå¤„ç† - ä½¿ç”¨Contextä¸‹è½½
    if input_path.startswith(('http://', 'https://')):
        if not ctx:
            raise ValueError("Context required for URL download")
        
        response = await ctx.http_request(method="GET", url=input_path, timeout=15)
        if response.status_code != 200:
            raise Exception(f"Failed to download URL: {response.status_code}")
        
        return base64.b64encode(response.content).decode('utf-8')
    
    # æ–‡ä»¶è·¯å¾„
    if _is_file_path(input_path):
        with open(input_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')
    
    # é»˜è®¤å½“ä½œBase64
    return input_path


def _base64_to_numpy(data: str) -> np.ndarray:
    """Base64è½¬numpyæ•°ç»„ï¼ˆæœ¬åœ°OCRä½¿ç”¨ï¼‰"""
    if data.startswith('data:'):
        base64_data = data.split(',', 1)[1]
    else:
        base64_data = data
    
    image_bytes = base64.b64decode(base64_data)
    image = Image.open(io.BytesIO(image_bytes))
    
    # è½¬RGB + é™åˆ¶å¤§å°
    if image.mode != 'RGB':
        if image.mode == 'RGBA':
            bg = Image.new('RGB', image.size, (255, 255, 255))
            bg.paste(image, mask=image.split()[-1])
            image = bg
        else:
            image = image.convert('RGB')
    
    # é™åˆ¶å›¾åƒå¤§å°
    if image.width * image.height > 4096 * 4096:
        scale = (4096 * 4096 / (image.width * image.height)) ** 0.5
        new_size = (int(image.width * scale), int(image.height * scale))
        image = image.resize(new_size, Image.LANCZOS)
    
    return np.array(image)


def _is_file_path(path: str) -> bool:
    """ç®€å•çš„æ–‡ä»¶è·¯å¾„åˆ¤æ–­"""
    return (path.startswith(('/', './', '../', '~')) or 
            (len(path) > 3 and path[1] == ':'))


def _is_base64_like(s: str) -> bool:
    """ç®€å•çš„Base64æ ¼å¼æ£€æŸ¥"""
    return len(s) > 10 and len(s) % 4 == 0 and re.match(r'^[A-Za-z0-9+/]*={0,2}$', s)


def _detect_file_type(input_path: str) -> int:
    """æ£€æµ‹æ–‡ä»¶ç±»å‹ (0=PDF, 1=Image)"""
    lower_path = input_path.lower()
    
    if 'application/pdf' in lower_path or lower_path.endswith('.pdf'):
        return 0
    
    # Base64 PDFæ£€æŸ¥
    if _is_base64_like(input_path) and input_path.startswith('JVBERi'):
        return 0
    
    return 1  # é»˜è®¤å›¾åƒ


# ==================== æœ¬åœ°OCRå¼•æ“ï¼ˆç®€åŒ–ç‰ˆï¼‰ ====================

@contextmanager
def _suppress_output():
    """æŠ‘åˆ¶PaddleOCRè¾“å‡º"""
    original = sys.stdout
    sys.stdout = StringIO()
    try:
        yield
    finally:
        sys.stdout = original


def _get_ocr_engine():
    """è·å–OCRå¼•æ“å®ä¾‹"""
    global _ocr_engine
    if _ocr_engine is None:
        if not LOCAL_OCR_AVAILABLE:
            raise RuntimeError("PaddleOCR not available. Please install paddleocr.")
        with _suppress_output():
            _ocr_engine = PaddleOCR(
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                use_textline_orientation=False,
                text_det_limit_type="min",
                text_det_limit_side_len=736,
                text_detection_model_name="PP-OCRv5_mobile_det",
                text_recognition_model_name="PP-OCRv5_mobile_rec"
            )
    return _ocr_engine


def _get_structure_engine():
    """è·å–ç»“æ„åˆ†æå¼•æ“å®ä¾‹"""
    global _structure_engine
    if _structure_engine is None:
        if not LOCAL_OCR_AVAILABLE:
            raise RuntimeError("PaddleOCR not available. Please install paddleocr.")
        with _suppress_output():
            _structure_engine = PPStructureV3(
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                use_chart_recognition=False,
                use_seal_recognition=False,  
                use_table_recognition=False,    
                text_detection_model_name="PP-OCRv5_mobile_det",
                text_recognition_model_name="PP-OCRv5_mobile_rec",
                layout_detection_model_name="PP-DocLayout-M",  
                device="cpu"
            )
    return _structure_engine


# ==================== APIè°ƒç”¨ï¼ˆä½¿ç”¨Contextç®€åŒ–ï¼‰ ====================

async def _call_aistudio_api(input_data: str, ctx: Context, **options) -> dict:
    """è°ƒç”¨API - ç»Ÿä¸€æ”¯æŒAI Studioå’Œæœ¬åœ°æœåŠ¡"""
    if not _api_config:
        raise ValueError("API not configured")
    
    # æ„å»ºè¯·æ±‚payload
    payload = {
        'file': input_data,
        'fileType': _detect_file_type(input_data)
    }
    
    # OCRæœåŠ¡çš„é¢å¤–å‚æ•°
    if _api_config['service_type'] == 'ocr':
        payload.update({
            'useDocOrientationClassify': options.get('useDocOrientationClassify', False),
            'useDocUnwarping': options.get('useDocUnwarping', False),
            'useTextlineOrientation': options.get('useTextlineOrientation', False)
        })
    
    # æ™ºèƒ½æ„å»ºè¯·æ±‚å¤´ - æœ¬åœ°æœåŠ¡ä¸éœ€è¦token
    headers = {'Content-Type': 'application/json'}
    if not _api_config['is_local_service'] and _api_config['token']:
        headers['Authorization'] = f'token {_api_config["token"]}'
    
    # ä½¿ç”¨Contextå‘é€HTTPè¯·æ±‚
    response = await ctx.http_request(
        method="POST",
        url=_api_config['url'],
        headers=headers,
        json=payload,
        timeout=_api_config['timeout']
    )
    
    if response.status_code != 200:
        service_type = "æœ¬åœ°æœåŠ¡" if _api_config['is_local_service'] else "AI Studio"
        raise Exception(f"{service_type} API error {response.status_code}: {response.text}")
    
    return response.json()['result']


# ==================== ç»“æœè§£æï¼ˆç®€åŒ–ç‰ˆï¼‰ ====================

def _parse_ocr_result(raw_result) -> dict:
    """è§£æOCRç»“æœ - ç»Ÿä¸€æ ¼å¼"""
    if is_api_mode():
        return _parse_api_ocr(raw_result)
    else:
        return _parse_local_ocr(raw_result)


def _parse_api_ocr(api_result: dict) -> dict:
    """è§£ææ˜Ÿæ²³API OCRç»“æœ"""
    if not api_result.get('ocrResults'):
        return {"text": "", "confidence": 0, "blocks": [], "text_type": "api", "det_params": None}
    
    texts, confidences, blocks = [], [], []
    
    for ocr_result in api_result['ocrResults']:
        pruned = ocr_result.get('prunedResult', {})
        
        if isinstance(pruned, dict):
            for i, text in enumerate(pruned.get('rec_texts', [])):
                if text and text.strip():
                    conf = pruned.get('rec_scores', [])[i] if i < len(pruned.get('rec_scores', [])) else 0
                    texts.append(text.strip())
                    confidences.append(conf)
                    
                    block = {"text": text.strip(), "confidence": round(conf, 3)}
                    
                    # æ·»åŠ è¾¹ç•Œæ¡†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    rec_boxes = pruned.get('rec_boxes', [])
                    if i < len(rec_boxes) and rec_boxes[i] is not None:
                        bbox = _normalize_bbox(rec_boxes[i])
                        if bbox:
                            block["bbox"] = bbox
                    
                    blocks.append(block)
        elif isinstance(pruned, str) and pruned.strip():
            texts.append(pruned.strip())
            blocks.append({"text": pruned.strip(), "confidence": None})
    
    return {
        "text": "\n".join(texts),
        "confidence": sum(confidences) / len(confidences) if confidences else 0,
        "blocks": blocks,
        "text_type": "api", 
        "det_params": api_result.get('ocrResults', [{}])[0].get('prunedResult', {}).get('text_det_params')
    }


def _parse_local_ocr(raw_result) -> dict:
    """è§£ææœ¬åœ°OCRç»“æœ"""
    if not raw_result or not raw_result[0]:
        return {"text": "", "confidence": 0, "blocks": [], "text_type": "unknown", "det_params": None}
    
    ocr_result = raw_result[0]
    
    # v5æ ¼å¼å¤„ç†
    def safe_get(obj, key, default=None):
        if hasattr(obj, key):
            return getattr(obj, key)
        elif isinstance(obj, dict):
            return obj.get(key, default)
        return default
    
    rec_texts = safe_get(ocr_result, 'rec_texts', [])
    rec_scores = safe_get(ocr_result, 'rec_scores', [])
    rec_boxes = safe_get(ocr_result, 'rec_boxes', [])
    rec_polys = safe_get(ocr_result, 'rec_polys', [])
    
    # æå–å…ƒæ•°æ®
    text_type = safe_get(ocr_result, 'text_type', 'general')
    det_params = safe_get(ocr_result, 'text_det_params', {})
    
    texts, confidences, blocks = [], [], []
    
    for i, text in enumerate(rec_texts):
        if text and text.strip():
            conf = rec_scores[i] if i < len(rec_scores) else 0
            texts.append(text.strip())
            confidences.append(conf)
            
            block = {"text": text.strip(), "confidence": round(conf, 3)}
            
            # ç»Ÿä¸€å¤„ç†è¾¹ç•Œæ¡† - ä¼˜å…ˆä½¿ç”¨rec_boxes
            bbox = None
            if i < len(rec_boxes) and rec_boxes[i] is not None:
                bbox = _normalize_bbox(rec_boxes[i])
            elif i < len(rec_polys) and rec_polys[i] is not None:
                bbox = _normalize_bbox(rec_polys[i])
            
            if bbox:
                block["bbox"] = bbox
            
            blocks.append(block)
    
    # å¦‚æœä¸Šè¿°v5æ ¼å¼è§£æå¤±è´¥ï¼Œå°è¯•é—ç•™æ ¼å¼
    if not texts and isinstance(raw_result[0], list):
        legacy_result = _parse_legacy_ocr_format(raw_result[0])
        legacy_result.update({"text_type": "legacy", "det_params": None})
        return legacy_result
    
    return {
        "text": "\n".join(texts),
        "confidence": sum(confidences) / len(confidences) if confidences else 0,
        "blocks": blocks,
        "text_type": text_type,
        "det_params": det_params
    }


def _parse_legacy_ocr_format(text_lines) -> dict:
    """è§£æé—ç•™OCRæ ¼å¼ï¼ˆæ—§ç‰ˆæœ¬å…¼å®¹ï¼‰"""
    texts, confidences, blocks = [], [], []
    
    for line_result in text_lines:
        if isinstance(line_result, list) and len(line_result) >= 2:
            bbox_data = line_result[0]  # è¾¹ç•Œæ¡†
            text_data = line_result[1]  # æ–‡æœ¬å’Œç½®ä¿¡åº¦
            
            if isinstance(text_data, tuple) and len(text_data) >= 2:
                text, confidence = text_data[0], text_data[1]
                if text and text.strip():
                    texts.append(text.strip())
                    confidences.append(confidence)
                    
                    block = {
                        "text": text.strip(),
                        "confidence": round(confidence, 3) if confidence > 0 else None
                    }
                    
                    # æ·»åŠ è¾¹ç•Œæ¡†ï¼ˆé—ç•™æ ¼å¼ï¼‰
                    if bbox_data and len(bbox_data) >= 4:
                        bbox = _normalize_bbox(bbox_data)
                        if bbox:
                            block["bbox"] = bbox
                    
                    blocks.append(block)
        
    return {
        "text": "\n".join(texts),
        "confidence": sum(confidences) / len(confidences) if confidences else 0,
        "blocks": blocks
    }


def _normalize_bbox(bbox) -> list:
    """æ ‡å‡†åŒ–è¾¹ç•Œæ¡†æ ¼å¼ - è½¬æ¢ä¸º [x1, y1, x2, y2]"""
    try:
        # å¤„ç†numpyæ•°ç»„
        if hasattr(bbox, 'tolist'):
            bbox = bbox.tolist()
        
        if not isinstance(bbox, (list, tuple)) or len(bbox) < 4:
            return None
        
        # å¦‚æœå·²ç»æ˜¯4ä¸ªåæ ‡æ ¼å¼ [x1,y1,x2,y2]
        if len(bbox) == 4 and all(isinstance(coord, (int, float)) for coord in bbox):
            return [round(float(coord), 1) for coord in bbox]
        
        # å¦‚æœæ˜¯8ä¸ªåæ ‡çš„å¤šè¾¹å½¢æ ¼å¼ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
        elif len(bbox) == 4 and all(isinstance(point, (list, tuple)) and len(point) == 2 for point in bbox):
            x_coords = [float(point[0]) for point in bbox]
            y_coords = [float(point[1]) for point in bbox]
            return [
                round(min(x_coords), 1), round(min(y_coords), 1),
                round(max(x_coords), 1), round(max(y_coords), 1)
            ]
        
        # å¦‚æœæ˜¯æ‰å¹³åŒ–çš„8ä¸ªåæ ‡ [x1,y1,x2,y2,x3,y3,x4,y4]
        elif len(bbox) == 8:
            x_coords = [float(bbox[i]) for i in range(0, 8, 2)]
            y_coords = [float(bbox[i]) for i in range(1, 8, 2)]
            return [
                round(min(x_coords), 1), round(min(y_coords), 1),
                round(max(x_coords), 1), round(max(y_coords), 1)
            ]
        
        # å°è¯•å¤„ç†åµŒå¥—æ•°ç»„æ ¼å¼ï¼ˆnumpyç‰¹æœ‰ï¼‰
        elif len(bbox) > 4 and hasattr(bbox[0], '__iter__'):
            # å±•å¹³æ‰€æœ‰åæ ‡ç‚¹
            all_points = []
            for item in bbox:
                if hasattr(item, 'tolist'):
                    item = item.tolist()
                if isinstance(item, (list, tuple)) and len(item) == 2:
                    all_points.append([float(item[0]), float(item[1])])
            
            if all_points:
                x_coords = [point[0] for point in all_points]
                y_coords = [point[1] for point in all_points]
                return [
                    round(min(x_coords), 1), round(min(y_coords), 1),
                    round(max(x_coords), 1), round(max(y_coords), 1)
                ]
        
        return None
    except (ValueError, TypeError, IndexError):
        return None


def _parse_structure_result(raw_result) -> dict:
    """è§£æç»“æ„åˆ†æç»“æœ - ç»Ÿä¸€æ ¼å¼"""
    if is_api_mode():
        return _parse_api_structure(raw_result)
    else:
        return _parse_local_structure(raw_result)


def _parse_api_structure(api_result: dict) -> dict:
    """è§£ææ˜Ÿæ²³APIç»“æ„ç»“æœ"""
    if not api_result.get('layoutParsingResults'):
        return {"markdown": "", "pages": [], "has_images": False}
    
    markdown_parts = []
    pages = []
    has_images = False
    
    for i, res in enumerate(api_result['layoutParsingResults']):
        markdown_data = res.get('markdown', {})
        if markdown_data.get('text'):
            text = markdown_data['text']
            markdown_parts.append(text)
            pages.append({
                "page": i,
                "content": text,
                "has_images": bool(markdown_data.get('images'))
            })
            if markdown_data.get('images'):
                has_images = True
    
    return {
        "markdown": "\n".join(markdown_parts),
        "pages": pages,
        "has_images": has_images
    }


def _parse_local_structure(raw_results) -> dict:
    """è§£ææœ¬åœ°ç»“æ„ç»“æœ"""
    if not raw_results:
        return {"markdown": "", "pages": [], "has_images": False}
    
    markdown_parts = []
    pages = []
    
    for i, result in enumerate(raw_results):
        text = ""
        if hasattr(result, 'markdown') and result.markdown:
            if isinstance(result.markdown, dict):
                text = result.markdown.get('text', str(result.markdown))
            else:
                text = str(result.markdown)
        
        if text:
            markdown_parts.append(text)
            pages.append({
                "page": i,
                "content": text,
                "has_images": False  # æœ¬åœ°æ¨¡å¼ç®€åŒ–å¤„ç†
            })
    
    return {
        "markdown": "\n".join(markdown_parts),
        "pages": pages,
        "has_images": False
    }


# ==================== æ ¼å¼åŒ–è¾“å‡ºï¼ˆç®€åŒ–ç‰ˆï¼‰ ====================

def format_ocr_output(result: dict, detailed: bool = False) -> str:
    """æ ¼å¼åŒ–OCRè¾“å‡º - ç»Ÿä¸€L1/L2æ ¼å¼"""
    if not result["text"].strip():
        error_msg = "âŒ No text detected"
        return error_msg if not detailed else json.dumps({
            "error": "No text detected", 
            "text": "", 
            "blocks": [],
            "meta": {"block_count": 0, "avg_confidence": 0, "text_type": "unknown"}
        }, ensure_ascii=False)
    
    if detailed:
        # L2: å®Œæ•´ç»“æ„åŒ–è¾“å‡º
        output = {
            "text": result["text"],
            "blocks": result["blocks"],
            "meta": {
                "block_count": len(result["blocks"]),
                "avg_confidence": round(result["confidence"], 3) if result["confidence"] > 0 else None,
                "has_coordinates": any("bbox" in block for block in result["blocks"]),
                "text_type": result.get("text_type", "unknown"),
                "engine_type": "api" if is_api_mode() else "local"
            }
        }
        
        # æ·»åŠ æ£€æµ‹å‚æ•°ï¼ˆå¦‚æœæœ‰ä¸”æœ‰ç”¨ï¼‰
        if result.get("det_params") and isinstance(result["det_params"], dict):
            # åªåŒ…å«å…³é”®å‚æ•°ï¼Œé¿å…ä¿¡æ¯è¿‡è½½
            key_params = {k: v for k, v in result["det_params"].items() 
                         if k in ['box_thresh', 'limit_side_len', 'limit_type', 'thresh']}
            if key_params:
                output["meta"]["detection_params"] = key_params
        
        return json.dumps(output, ensure_ascii=False, indent=2)
    else:
        # L1: ç®€æ´æ–‡æœ¬è¾“å‡º + å…³é”®ä¿¡æ¯
        output = result["text"]
        
        # æ·»åŠ ç®€æ´çš„å…ƒä¿¡æ¯
        info_parts = []
        if result["confidence"] > 0:
            info_parts.append(f"ç½®ä¿¡åº¦: {(result['confidence'] * 100):.1f}%")
        info_parts.append(f"{len(result['blocks'])}ä¸ªæ–‡æœ¬å—")
        if result.get("text_type") and result["text_type"] != "unknown":
            info_parts.append(f"ç±»å‹: {result['text_type']}")
        
        if info_parts:
            output += f"\n\nğŸ“Š {' | '.join(info_parts)}"
        
        return output


def format_structure_output(result: dict, detailed: bool = False) -> str:
    """æ ¼å¼åŒ–ç»“æ„åˆ†æè¾“å‡º - ç»Ÿä¸€L1/L2"""
    if not result["markdown"].strip():
        error_msg = "âŒ No document structure detected"
        return error_msg if not detailed else json.dumps({
            "error": "No structure detected", 
            "markdown": "", 
            "pages": [],
            "meta": {"page_count": 0, "has_images": False}
        }, ensure_ascii=False)
    
    if detailed:
        # L2: å®Œæ•´ç»“æ„åŒ–è¾“å‡º
        output = {
            "markdown": result["markdown"],
            "pages": result["pages"],
            "meta": {
                "page_count": len(result["pages"]),
                "has_images": result["has_images"],
                "engine_type": "api" if is_api_mode() else "local"
            }
        }
        return json.dumps(output, ensure_ascii=False, indent=2)
    else:
        # L1: çº¯markdownè¾“å‡º
        return result["markdown"]


# ==================== MCPå·¥å…·æ³¨å†Œï¼ˆç®€åŒ–ç‰ˆï¼‰ ====================

def register_tools(mcp, engine_type: str = "local", **api_config):
    """æ³¨å†ŒMCPå·¥å…· - æ”¯æŒæœ¬åœ°ã€AI Studioã€æœ¬åœ°æœåŠ¡ä¸‰ç§æ¨¡å¼"""
    
    # é…ç½®APIï¼ˆå¦‚æœæ˜¯APIæ¨¡å¼ï¼‰
    if engine_type in ["aistudio", "local_service"]:
        configure_api(**api_config)
    
    # æ™ºèƒ½æè¿°å¼•æ“ç±»å‹
    if is_api_mode():
        if _api_config['is_local_service']:
            engine_desc = "æœ¬åœ°æœåŠ¡API"
        else:
            engine_desc = "æ˜Ÿæ²³API"
    else:
        engine_desc = "æœ¬åœ°PaddleOCR"
    
    @mcp.tool()
    async def ocr_text(
        input_path: str, 
        output_mode: str = "simple",
        file_type: str = "auto",
        useDocOrientationClassify: bool = True,
        useDocUnwarping: bool = True,
        ctx: Optional[Context] = None
    ) -> str:
        f"""Extract text from images and PDFs using {engine_desc}.
        
        Args:
            input_path: æ–‡ä»¶è·¯å¾„ã€URLæˆ–Base64æ•°æ®
            output_mode: "simple" (L1ç®€æ´) æˆ– "detailed" (L2è¯¦ç»†)
            file_type: æ–‡ä»¶ç±»å‹ ("auto", "pdf", "image") - APIæ¨¡å¼
            useDocOrientationClassify: æ–‡æ¡£æ–¹å‘åˆ†ç±» - APIæ¨¡å¼
            useDocUnwarping: æ–‡æ¡£å›¾åƒæ ¡æ­£ - APIæ¨¡å¼
        """
        try:
            # å‡†å¤‡APIå‚æ•°
            api_kwargs = {
                "file_type": file_type,
                "useDocOrientationClassify": useDocOrientationClassify,
                "useDocUnwarping": useDocUnwarping
            }
            
            # ä½¿ç”¨å¼‚æ­¥è¾“å…¥å¤„ç†ï¼ˆæ”¯æŒURLä¸‹è½½ï¼‰
            if is_api_mode():
                processed_input = await process_input_async(input_path, ctx)
            else:
                processed_input = process_input(input_path)
            
            if is_api_mode():
                # APIæ¨¡å¼ (AI Studio æˆ–æœ¬åœ°æœåŠ¡)
                if not ctx:
                    raise ValueError("Context required for API mode")
                raw_result = await _call_aistudio_api(processed_input, ctx, **api_kwargs)
            else:
                # æœ¬åœ°OCRæ¨¡å¼
                ocr = _get_ocr_engine()
                with _suppress_output():
                    raw_result = ocr.predict(processed_input)
            
            result = _parse_ocr_result(raw_result)
            return format_ocr_output(result, output_mode == "detailed")
            
        except Exception as e:
            error_msg = f"OCR failed: {str(e)}"
            return error_msg if output_mode == "simple" else json.dumps({"error": error_msg}, ensure_ascii=False)
    
    @mcp.tool()
    async def analyze_structure(
        input_path: str,
        output_mode: str = "detailed",
        file_type: str = "auto",
        ctx: Optional[Context] = None
    ) -> str:
        f"""Analyze document structure using {engine_desc}.
        
        Args:
            input_path: æ–‡ä»¶è·¯å¾„ã€URLæˆ–Base64æ•°æ®
            output_mode: "simple" (L1çº¯markdown) æˆ– "detailed" (L2ç»“æ„åŒ–)
            file_type: æ–‡ä»¶ç±»å‹ ("auto", "pdf", "image") - APIæ¨¡å¼
        """
        try:
            # å‡†å¤‡APIå‚æ•°
            api_kwargs = {"file_type": file_type}
            
            # ä½¿ç”¨å¼‚æ­¥è¾“å…¥å¤„ç†ï¼ˆæ”¯æŒURLä¸‹è½½ï¼‰
            if is_api_mode():
                processed_input = await process_input_async(input_path, ctx)
            else:
                processed_input = process_input(input_path)
            
            if is_api_mode():
                # APIæ¨¡å¼ (AI Studio æˆ–æœ¬åœ°æœåŠ¡)
                if not ctx:
                    raise ValueError("Context required for API mode")
                raw_result = await _call_aistudio_api(processed_input, ctx, **api_kwargs)
            else:
                # æœ¬åœ°ç»“æ„åˆ†ææ¨¡å¼
                structure = _get_structure_engine()
                with _suppress_output():
                    raw_result = structure.predict(processed_input)
            
            result = _parse_structure_result(raw_result)
            return format_structure_output(result, output_mode == "detailed")
            
        except Exception as e:
            error_msg = f"Structure analysis failed: {str(e)}"
            return error_msg if output_mode == "simple" else json.dumps({"error": error_msg}, ensure_ascii=False) 