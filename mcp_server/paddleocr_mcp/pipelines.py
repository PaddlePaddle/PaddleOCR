# æ ‡å‡†åº“å¯¼å…¥
import abc
import asyncio
import base64
import io
import json
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import httpx
import numpy as np
import filetype
from PIL import Image
from fastmcp import Context, Image as FastMCPImage


# ==================== åŸºç¡€æŠ½è±¡ç±» ====================


class PipelineHandler(abc.ABC):
    """
    ç»Ÿä¸€äº§çº¿å¤„ç†å™¨ - æ¨¡æ¿æ–¹æ³•æ¨¡å¼

    æ¨¡æ¿: å®šä¹‰æ‰€æœ‰äº§çº¿çš„ç»Ÿä¸€å¤„ç†æµç¨‹
    å¥‘çº¦: å¼ºåˆ¶å­ç±»å®ç°å·®å¼‚åŒ–çš„è§£æå’Œæ ¼å¼åŒ–é€»è¾‘
    """

    def __init__(self, engines):
        self.engines = engines

    async def process(
        self, input_data: str, output_mode: str, ctx: Optional[Context] = None
    ) -> Union[str, List]:
        """
        [æ¨¡æ¿] ç»Ÿä¸€çš„äº§çº¿å¤„ç†æµç¨‹

        åŒ…å«95%çš„å…±åŒé€»è¾‘ï¼š
        - æ—¥å¿—è®°å½•
        - API/Localæ¨¡å¼åˆ¤æ–­
        - å¼•æ“è°ƒç”¨
        - é”™è¯¯å¤„ç†
        - ç»“æœæ ¼å¼åŒ–
        """
        try:
            # 1. å¼€å§‹å¤„ç†æ—¥å¿—
            if ctx:
                pipeline_name = self.get_pipeline_name()
                source_desc = self._get_source_description()
                await ctx.info(
                    f"Starting {pipeline_name} processing using {source_desc}"
                )

            # 2. æ ¹æ®æ¨¡å¼è°ƒç”¨ä¸åŒçš„å¤„ç†é€»è¾‘
            if self.engines.is_api_mode():
                if not ctx:
                    raise ValueError("Context required for API mode")
                raw_result = await self._call_api(input_data)
                result = self._parse_api_result(raw_result)
            else:
                # æœ¬åœ°æ¨¡å¼ï¼šè¾“å…¥é¢„å¤„ç†
                processed_input = self._process_input_for_local(input_data)

                # è·å–å¼•æ“å¹¶å¼‚æ­¥æ‰§è¡Œ
                engine = self.engines.get_engine(self.get_engine_name())
                loop = asyncio.get_running_loop()
                raw_result = await loop.run_in_executor(
                    None, engine.predict, processed_input
                )

                result = self._parse_local_result(raw_result)

            # 3. å®Œæˆå¤„ç†æ—¥å¿—
            if ctx:
                await self._log_completion_stats(ctx, result)

            # 4. æ ¼å¼åŒ–è¾“å‡º
            return self._format_output(result, output_mode == "detailed")

        except Exception as e:
            # 5. ç»Ÿä¸€é”™è¯¯å¤„ç†
            if ctx:
                await ctx.error(f"{self.get_pipeline_name()} failed: {str(e)}")
            return self._handle_error(str(e), output_mode)

    # ==================== [å¥‘çº¦] å­ç±»å¿…é¡»å®ç°çš„æŠ½è±¡æ–¹æ³• ====================

    @abc.abstractmethod
    def get_pipeline_name(self) -> str:
        """è·å–äº§çº¿åç§° (ç”¨äºæ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯)"""
        pass

    @abc.abstractmethod
    def get_engine_name(self) -> str:
        """è·å–å¼•æ“åç§° (æœ¬åœ°æ¨¡å¼ä½¿ç”¨)"""
        pass

    @abc.abstractmethod
    def _parse_api_result(self, api_result: Dict) -> Dict:
        """è§£æAPIè¿”å›çš„åŸå§‹ç»“æœä¸ºç»Ÿä¸€æ ¼å¼"""
        pass

    @abc.abstractmethod
    def _parse_local_result(self, local_result: Any) -> Dict:
        """è§£ææœ¬åœ°å¼•æ“è¿”å›çš„åŸå§‹ç»“æœä¸ºç»Ÿä¸€æ ¼å¼"""
        pass

    @abc.abstractmethod
    def _format_output(self, result: Dict, detailed: bool) -> Union[str, List]:
        """å°†ç»Ÿä¸€ç»“æœæ ¼å¼åŒ–ä¸ºL1(simple)æˆ–L2(detailed)è¾“å‡º"""
        pass

    @abc.abstractmethod
    async def _log_completion_stats(self, ctx: Context, result: Dict):
        """è®°å½•å¤„ç†å®Œæˆçš„ç»Ÿè®¡ä¿¡æ¯"""
        pass

    # ==================== [æ¨¡æ¿] å…±äº«çš„è¾…åŠ©æ–¹æ³• ====================

    def _get_source_description(self) -> str:
        """è·å–æ•°æ®æºæè¿°"""
        if self.engines.is_api_mode():
            return (
                "ç”¨æˆ·æœåŠ¡API"
                if self.engines._api_config["is_user_service"]
                else "æ˜Ÿæ²³API"
            )
        else:
            return "æœ¬åœ°PaddleOCR"

    async def _call_api(self, input_data: str) -> dict:
        """è°ƒç”¨API - ç»Ÿä¸€çš„APIè°ƒç”¨é€»è¾‘"""
        if not self.engines._api_config:
            raise ValueError("API not configured")

        # æ–‡ä»¶è·¯å¾„ -> base64ï¼Œå…¶ä»–åŸæ ·ä¼ é€’
        if self._is_file_path(input_data):
            with open(input_data, "rb") as f:
                file_data = base64.b64encode(f.read()).decode("ascii")
        else:
            file_data = input_data

        # APIéœ€è¦æ–‡ä»¶ç±»å‹å‚æ•°
        payload = {"file": file_data, "fileType": self._detect_file_type(input_data)}

        # æ„å»ºheaders
        headers = {"Content-Type": "application/json"}
        if self.engines._api_config["token"]:
            headers["Authorization"] = f'token {self.engines._api_config["token"]}'

        # å‘é€è¯·æ±‚
        async with httpx.AsyncClient() as client:
            response = await client.post(
                self.engines._api_config["url"],
                headers=headers,
                json=payload,
                timeout=self.engines._api_config.get("timeout", 30),
            )

        if response.status_code != 200:
            raise RuntimeError(f"API error {response.status_code}: {response.text}")

        response_json = response.json()
        error_code = response_json.get("errorCode", 0)

        if error_code != 0:
            error_msg = response_json.get("errorMsg", "Unknown API error")
            raise RuntimeError(f"API failed (errorCode: {error_code}): {error_msg}")

        return response_json["result"]

    def _process_input_for_local(self, input_data: str):
        """æœ¬åœ°æ¨¡å¼è¾“å…¥å¤„ç†ï¼šbase64è½¬numpyï¼Œæ–‡ä»¶è·¯å¾„ç›´æ¥ç”¨"""
        if self._is_base64(input_data):
            if input_data.startswith("data:"):
                base64_data = input_data.split(",", 1)[1]
            else:
                base64_data = input_data
            image_bytes = base64.b64decode(base64_data)
            image = Image.open(io.BytesIO(image_bytes))
            return np.array(image)
        return input_data

    def _handle_error(self, error_msg: str, output_mode: str) -> str:
        """ç»Ÿä¸€é”™è¯¯å¤„ç†"""
        pipeline_error = f"{self.get_pipeline_name()} failed: {error_msg}"
        return (
            pipeline_error
            if output_mode == "simple"
            else json.dumps({"error": pipeline_error}, ensure_ascii=False)
        )

    # ==================== è¾“å…¥å¤„ç†è¾…åŠ©æ–¹æ³• ====================

    @staticmethod
    def _is_file_path(data: str) -> bool:
        """ç®€å•æ–‡ä»¶è·¯å¾„åˆ¤æ–­"""
        return data.startswith(("/", "./", "../")) or "\\" in data

    @staticmethod
    def _is_base64(data: str) -> bool:
        """ç®€å•base64åˆ¤æ–­"""
        return (
            len(data) > 100
            and data.replace("+", "").replace("/", "").replace("=", "").isalnum()
        )

    @staticmethod
    def _detect_file_type(input_data: str) -> int:
        """æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼š0=PDFï¼Œ1=å›¾ç‰‡"""
        # æ–‡ä»¶è·¯å¾„ï¼šæ£€æŸ¥æ‰©å±•å
        if PipelineHandler._is_file_path(input_data):
            return 0 if input_data.lower().endswith(".pdf") else 1

        # Base64ï¼šæ£€æŸ¥PDFé­”æœ¯å­—èŠ‚
        if PipelineHandler._is_base64(input_data) and input_data.startswith("JVBERi"):
            return 0

        # é»˜è®¤å›¾ç‰‡
        return 1


# ==================== å…·ä½“äº§çº¿å®ç° ====================


class OcrPipeline(PipelineHandler):
    """OCRäº§çº¿ - ä¸“æ³¨çº¯æ–‡æœ¬æå–"""

    def get_pipeline_name(self) -> str:
        return "OCR"

    def get_engine_name(self) -> str:
        return "ocr"

    def _parse_api_result(self, api_result: Dict) -> Dict:
        """è§£ææ˜Ÿæ²³API OCRç»“æœ"""
        ocr_results = api_result["ocrResults"]
        if not ocr_results:
            return {
                "text": "",
                "confidence": 0,
                "blocks": [],
                "text_type": "api",
            }

        # ç›´æ¥æå–å’Œç»„è£…
        all_texts, all_confidences, blocks = [], [], []

        for ocr_result in ocr_results:
            pruned = ocr_result["prunedResult"]

            # prunedResultç¡®å®šæ˜¯å­—å…¸ç±»å‹
            texts = pruned.get("rec_texts", [])
            scores = pruned.get("rec_scores", [])
            boxes = pruned.get("rec_boxes", [])

            for i, text in enumerate(texts):
                if text and text.strip():
                    conf = scores[i] if i < len(scores) else 0
                    all_texts.append(text.strip())
                    all_confidences.append(conf)

                    block = {"text": text.strip(), "confidence": round(conf, 3)}
                    if i < len(boxes) and boxes[i]:
                        block["bbox"] = boxes[i]
                    blocks.append(block)

        return {
            "text": "\n".join(all_texts),
            "confidence": (
                sum(all_confidences) / len(all_confidences) if all_confidences else 0
            ),
            "blocks": blocks,
            "text_type": "api",
        }

    def _parse_local_result(self, raw_result) -> Dict:
        """è§£ææœ¬åœ°OCRç»“æœ"""
        if not raw_result or not raw_result[0]:
            return {
                "text": "",
                "confidence": 0,
                "blocks": [],
                "text_type": "local",
            }

        result = raw_result[0]
        texts = result.get("rec_texts", [])
        scores = result.get("rec_scores", [])
        boxes = result.get("rec_boxes", []) or result.get("rec_polys", [])

        if not texts:
            return {
                "text": "",
                "confidence": 0,
                "blocks": [],
                "text_type": "local",
            }

        # ç›´æ¥ç»„è£…
        clean_texts, confidences, blocks = [], [], []

        for i, text in enumerate(texts):
            if text and text.strip():
                conf = scores[i] if i < len(scores) else 0
                clean_texts.append(text.strip())
                confidences.append(conf)

                block = {"text": text.strip(), "confidence": round(conf, 3)}
                if i < len(boxes) and boxes[i]:
                    block["bbox"] = boxes[i]
                blocks.append(block)

        return {
            "text": "\n".join(clean_texts),
            "confidence": sum(confidences) / len(confidences) if confidences else 0,
            "blocks": blocks,
            "text_type": result.get("text_type", "local"),
        }

    def _format_output(self, result: Dict, detailed: bool) -> str:
        """æ ¼å¼åŒ–OCRè¾“å‡º - L1æ ¸å¿ƒä¿¡æ¯ï¼ŒL2å®Œæ•´æ•°æ®"""
        if not result["text"].strip():
            return (
                "âŒ No text detected"
                if not detailed
                else json.dumps({"error": "No text detected"}, ensure_ascii=False)
            )

        if detailed:
            # L2: è¿”å›æ‰€æœ‰
            return json.dumps(result, ensure_ascii=False, indent=2)
        else:
            # L1: æ ¸å¿ƒæ–‡æœ¬ + å…³é”®ç»Ÿè®¡
            confidence = result["confidence"]
            block_count = len(result["blocks"])

            output = result["text"]
            if confidence > 0:
                output += (
                    f"\n\nğŸ“Š ç½®ä¿¡åº¦: {(confidence * 100):.1f}% | {block_count}ä¸ªæ–‡æœ¬å—"
                )

            return output

    async def _log_completion_stats(self, ctx: Context, result: Dict):
        """è®°å½•OCRå®Œæˆç»Ÿè®¡"""
        text_length = len(result["text"])
        block_count = len(result["blocks"])
        await ctx.info(
            f"OCR completed: {text_length} characters, {block_count} text blocks"
        )


class StructurePipeline(PipelineHandler):
    """ç»“æ„åˆ†æäº§çº¿ - ä¸“æ³¨æ–‡æ¡£ç»“æ„å’Œç›¸å…³å›¾ç‰‡"""

    def get_pipeline_name(self) -> str:
        return "Structure analysis"

    def get_engine_name(self) -> str:
        return "structure"

    def _parse_api_result(self, api_result: Dict) -> Dict:
        """è§£ææ˜Ÿæ²³APIç»“æ„ç»“æœ"""
        layout_results = api_result["layoutParsingResults"]
        if not layout_results:
            return {
                "markdown": "",
                "pages": [],
                "has_images": False,
                "images": [],
                "referenced_images": [],
            }

        markdown_parts, pages, all_images = [], [], []
        referenced_images = []

        for i, res in enumerate(layout_results):
            markdown_data = res["markdown"]
            page_images = []

            if markdown_data.get("text"):
                text = markdown_data["text"]
                markdown_parts.append(text)

                # æ”¶é›†å½“å‰é¡µé¢çš„å›¾ç‰‡
                if markdown_data.get("images"):
                    sorted_images = sorted(markdown_data["images"].items())
                    page_images = [url for filename, url in sorted_images]
                    all_images.extend(page_images)

                    # æå–å½“å‰é¡µé¢markdownä¸­å®é™…å¼•ç”¨çš„æ‰€æœ‰å›¾ç‰‡
                    page_referenced_images = (
                        self._extract_referenced_images_from_markdown(
                            text, markdown_data["images"]
                        )
                    )
                    referenced_images.extend(page_referenced_images)

                page = {
                    "page": i,
                    "content": text,
                    "has_images": bool(page_images),
                    "images": page_images,
                }
                pages.append(page)

        return {
            "markdown": "\n".join(markdown_parts),
            "pages": pages,
            "has_images": bool(all_images),
            "images": all_images,
            "referenced_images": referenced_images,
        }

    def _parse_local_result(self, raw_results) -> Dict:
        """è§£ææœ¬åœ°ç»“æ„ç»“æœ"""
        if not raw_results:
            return {"markdown": "", "pages": [], "has_images": False, "images": []}

        markdown_parts, pages = [], []

        for i, result in enumerate(raw_results):
            text = ""
            if hasattr(result, "markdown") and result.markdown:
                text = (
                    result.markdown.get("text", str(result.markdown))
                    if isinstance(result.markdown, dict)
                    else str(result.markdown)
                )

            if text:
                markdown_parts.append(text)
                pages.append({"page": i, "content": text, "has_images": False})

        return {
            "markdown": "\n".join(markdown_parts),
            "pages": pages,
            "has_images": False,
            "images": [],
        }

    def _format_output(self, result: Dict, detailed: bool) -> Union[str, List]:
        """æ ¼å¼åŒ–ç»“æ„åˆ†æè¾“å‡º - L1/L2éƒ½åŒ…å«å›¾ç‰‡"""
        if not result["markdown"].strip():
            return (
                "âŒ No document structure detected"
                if not detailed
                else json.dumps({"error": "No structure detected"}, ensure_ascii=False)
            )

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ··åˆå†…å®¹ä¼ è¾“ï¼ˆAPIæ¨¡å¼ + æœ‰å¼•ç”¨å›¾ç‰‡ï¼‰
        if (
            result.get("referenced_images")
            and self.engines.is_api_mode()
            and not detailed
        ):
            try:
                content_list = []

                # æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆæ— å›¾ç‰‡å¼•ç”¨é¿å…é‡å¤ï¼‰
                text_content = self._format_text_only(result, include_image_refs=False)
                content_list.append(text_content)

                # æ·»åŠ æ‰€æœ‰åœ¨markdownä¸­å¼•ç”¨çš„å›¾ç‰‡
                for target_image in result["referenced_images"]:
                    image_content = self._process_image_for_transmission(target_image)
                    if image_content:
                        content_list.append(image_content)

                return content_list
            except Exception as e:
                raise RuntimeError(f"Failed to process mixed content: {str(e)}") from e

        # æ ‡å‡†æ–‡æœ¬è¿”å›
        if detailed:
            # L2: ç§»é™¤å¤§ä½“ç§¯å›¾ç‰‡æ•°æ®ï¼Œåªä¿ç•™å…ƒæ•°æ®
            cleaned_result = {k: v for k, v in result.items() if k != "images"}
            return json.dumps(cleaned_result, ensure_ascii=False, indent=2)
        else:
            # L1: çº¯markdown + å›¾ç‰‡å¼•ç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
            return self._format_text_only(result, include_image_refs=True)

    def _format_text_only(self, result: Dict, include_image_refs: bool = True) -> str:
        """æ ¼å¼åŒ–çº¯æ–‡æœ¬è¾“å‡º"""
        markdown = result["markdown"]

        if result["images"] and include_image_refs:
            image_refs = "\n\nğŸ“¸ **Images**: " + ", ".join(
                f"[img{i+1}]({url})" for i, url in enumerate(result["images"])
            )
            markdown += image_refs

        return markdown

    def _process_image_for_transmission(
        self, target_image: str
    ) -> Optional[FastMCPImage]:
        """å¤„ç†å›¾ç‰‡ç”¨äºä¼ è¾“ - ä½¿ç”¨filetypeåº“è¿›è¡Œrobustæ ¼å¼æ£€æµ‹"""
        try:
            if target_image.startswith(("http://", "https://")):
                # URLï¼šä¸‹è½½å›¾ç‰‡
                import asyncio

                async def download_image():
                    async with httpx.AsyncClient() as client:
                        response = await client.get(target_image)
                        if response.status_code == 200:
                            # ä½¿ç”¨filetypeæ£€æµ‹å®é™…æ ¼å¼
                            image_data = response.content
                            detected_type = filetype.guess(image_data)
                            if detected_type and detected_type.mime.startswith(
                                "image/"
                            ):
                                format_type = detected_type.extension
                            else:
                                # ä»Content-Typeå¤´éƒ¨è·å–æ ¼å¼ä½œä¸ºfallback
                                format_type = response.headers.get(
                                    "content-type", "image/jpeg"
                                ).split("/")[-1]
                            return FastMCPImage(data=image_data, format=format_type)
                    return None

                # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
                try:
                    loop = asyncio.get_running_loop()
                    # è¿™é‡Œéœ€è¦å¤„ç†å¼‚æ­¥ï¼Œä½†ç”±äºæ··åˆå†…å®¹å¤„ç†çš„å¤æ‚æ€§ï¼Œæš‚æ—¶ç®€åŒ–
                    return None
                except RuntimeError:
                    return None
            else:
                # å‡è®¾ä¸ºbase64æ•°æ®ï¼šä½¿ç”¨filetypeè¿›è¡Œrobustæ£€æµ‹
                image_data = base64.b64decode(target_image)

                # ä½¿ç”¨filetypeåº“è¿›è¡Œæ ¼å¼æ£€æµ‹
                detected_type = filetype.guess(image_data)
                if detected_type and detected_type.mime.startswith("image/"):
                    format_type = detected_type.extension
                else:
                    # å¦‚æœfiletypeæ— æ³•è¯†åˆ«ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
                    format_type = "jpeg"

                return FastMCPImage(data=image_data, format=format_type)
        except Exception as e:
            import logging

            logging.getLogger(__name__).debug(
                f"Image processing failed for {target_image[:50]}...: {e}"
            )
            return None

    def _extract_referenced_images_from_markdown(
        self, markdown_text: str, available_images: Dict[str, str]
    ) -> List[str]:
        """ä»markdownæ–‡æœ¬ä¸­æå–å®é™…è¢«å¼•ç”¨çš„å›¾ç‰‡URL"""
        if not markdown_text or not available_images:
            return []

        # åŒ¹é…markdownä¸­çš„å›¾ç‰‡å¼•ç”¨ï¼š<img src="path" /> æˆ– ![alt](path)
        img_patterns = [
            r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>',  # HTML imgæ ‡ç­¾
            r"!\[[^\]]*\]\(([^)]+)\)",  # Markdownå›¾ç‰‡è¯­æ³•
        ]

        referenced_images = []
        for pattern in img_patterns:
            matches = re.findall(pattern, markdown_text)
            for img_path in matches:
                # æå–æ–‡ä»¶åï¼ˆå»æ‰è·¯å¾„å‰ç¼€ï¼‰
                img_filename = img_path.split("/")[-1]
                # åœ¨available_imagesä¸­æŸ¥æ‰¾å¯¹åº”çš„URL
                for filename, url in available_images.items():
                    if filename == img_filename or img_path.endswith(filename):
                        referenced_images.append(url)
                        break

        return referenced_images

    async def _log_completion_stats(self, ctx: Context, result: Dict):
        """è®°å½•ç»“æ„åˆ†æå®Œæˆç»Ÿè®¡"""
        page_count = len(result["pages"])
        image_count = len(result["images"])
        await ctx.info(
            f"Structure analysis completed: {page_count} pages, {image_count} images"
        )
