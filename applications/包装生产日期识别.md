# ä¸€ç§åŸºäºPaddleOCRçš„äº§å“åŒ…è£…ç”Ÿäº§æ—¥æœŸè¯†åˆ«æ¨¡å‹

- [1. é¡¹ç›®ä»‹ç»](#1-é¡¹ç›®ä»‹ç»)
- [2. ç¯å¢ƒæ­å»º](#2-ç¯å¢ƒæ­å»º)
- [3. æ•°æ®å‡†å¤‡](#3-æ•°æ®å‡†å¤‡)
- [4. ç›´æ¥ä½¿ç”¨PP-OCRv3æ¨¡å‹è¯„ä¼°](#4-ç›´æ¥ä½¿ç”¨PPOCRv3æ¨¡å‹è¯„ä¼°)
- [5. åŸºäºåˆæˆæ•°æ®finetune](#5-åŸºäºåˆæˆæ•°æ®finetune)
  - [5.1 Text Rendereræ•°æ®åˆæˆæ–¹æ³•](#51-TextRendereræ•°æ®åˆæˆæ–¹æ³•)
    - [5.1.1 ä¸‹è½½Text Rendererä»£ç ](#511-ä¸‹è½½TextRendererä»£ç )
    - [5.1.2 å‡†å¤‡èƒŒæ™¯å›¾ç‰‡](#512-å‡†å¤‡èƒŒæ™¯å›¾ç‰‡)
    - [5.1.3 å‡†å¤‡è¯­æ–™](#513-å‡†å¤‡è¯­æ–™)
    - [5.1.4 ä¸‹è½½å­—ä½“](#514-ä¸‹è½½å­—ä½“)
    - [5.1.5 è¿è¡Œæ•°æ®åˆæˆå‘½ä»¤](#515-è¿è¡Œæ•°æ®åˆæˆå‘½ä»¤)
  - [5.2 æ¨¡å‹è®­ç»ƒ](#52-æ¨¡å‹è®­ç»ƒ)
- [6. åŸºäºçœŸå®æ•°æ®finetune](#6-åŸºäºçœŸå®æ•°æ®finetune)
  - [6.1 pythonçˆ¬è™«è·å–æ•°æ®](#61-pythonçˆ¬è™«è·å–æ•°æ®)
  - [6.2 æ•°æ®æŒ–æ˜](#62-æ•°æ®æŒ–æ˜)
  - [6.3 æ¨¡å‹è®­ç»ƒ](#63-æ¨¡å‹è®­ç»ƒ)
- [7. åŸºäºåˆæˆ+çœŸå®æ•°æ®finetune](#7-åŸºäºåˆæˆ+çœŸå®æ•°æ®finetune)


## 1. é¡¹ç›®ä»‹ç»

äº§å“åŒ…è£…ç”Ÿäº§æ—¥æœŸæ˜¯è®¡ç®—æœºè§†è§‰å›¾åƒè¯†åˆ«æŠ€æœ¯åœ¨å·¥ä¸šåœºæ™¯ä¸­çš„ä¸€ç§åº”ç”¨ã€‚äº§å“åŒ…è£…ç”Ÿäº§æ—¥æœŸè¯†åˆ«æŠ€æœ¯è¦æ±‚èƒ½å¤Ÿå°†äº§å“ç”Ÿäº§æ—¥æœŸä»å¤æ‚èƒŒæ™¯ä¸­æå–å¹¶è¯†åˆ«å‡ºæ¥ï¼Œåœ¨ç‰©æµç®¡ç†ã€ç‰©èµ„ç®¡ç†ä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/d9e0533cc1df47ffa3bbe99de9e42639a3ebfa5bce834bafb1ca4574bf9db684)


- é¡¹ç›®éš¾ç‚¹

1. æ²¡æœ‰è®­ç»ƒæ•°æ®
2. å›¾åƒè´¨é‡å±‚æ¬¡ä¸é½: è§’åº¦å€¾æ–œã€å›¾ç‰‡æ¨¡ç³Šã€å…‰ç…§ä¸è¶³ã€è¿‡æ›ç­‰é—®é¢˜ä¸¥é‡

é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œ æœ¬ä¾‹é€‰ç”¨PP-OCRv3è¿™ä¸€å¼€æºè¶…è½»é‡OCRç³»ç»Ÿè¿›è¡ŒåŒ…è£…äº§å“ç”Ÿäº§æ—¥æœŸè¯†åˆ«ç³»ç»Ÿçš„å¼€å‘ã€‚ç›´æ¥ä½¿ç”¨PP-OCRv3è¿›è¡Œè¯„ä¼°çš„ç²¾åº¦ä¸º62.99%ã€‚ä¸ºæå‡è¯†åˆ«ç²¾åº¦ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨æ•°æ®åˆæˆå·¥å…·åˆæˆäº†3kæ•°æ®ï¼ŒåŸºäºè¿™éƒ¨åˆ†æ•°æ®è¿›è¡Œfinetuneï¼Œè¯†åˆ«ç²¾åº¦æå‡è‡³73.66%ã€‚ç”±äºåˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´çš„åˆ†å¸ƒå­˜åœ¨å·®å¼‚ï¼Œä¸ºè¿›ä¸€æ­¥æå‡ç²¾åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨ç½‘ç»œçˆ¬è™«é…åˆæ•°æ®æŒ–æ˜ç­–ç•¥å¾—åˆ°äº†1kå¸¦æ ‡ç­¾çš„çœŸå®æ•°æ®ï¼ŒåŸºäºçœŸå®æ•°æ®finetuneçš„ç²¾åº¦ä¸º71.33%ã€‚æœ€åï¼Œæˆ‘ä»¬ç»¼åˆä½¿ç”¨åˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®è¿›è¡Œfinetuneï¼Œå°†è¯†åˆ«ç²¾åº¦æå‡è‡³86.99%ã€‚å„ç­–ç•¥çš„ç²¾åº¦æå‡æ•ˆæœå¦‚ä¸‹ï¼š

| ç­–ç•¥ | ç²¾åº¦|
| :--------------- | :-------- |
| PP-OCRv3è¯„ä¼° | 62.99|
| åˆæˆæ•°æ®finetune | 73.66|
| çœŸå®æ•°æ®finetune | 71.33|
| çœŸå®+åˆæˆæ•°æ®finetune | 86.99|

AIStudioé¡¹ç›®é“¾æ¥ï¼š [ä¸€ç§åŸºäºPaddleOCRçš„åŒ…è£…ç”Ÿäº§æ—¥æœŸè¯†åˆ«æ–¹æ³•](https://aistudio.baidu.com/aistudio/projectdetail/4287736)

## 2. ç¯å¢ƒæ­å»º

æœ¬ä»»åŠ¡åŸºäºAistudioå®Œæˆ, å…·ä½“ç¯å¢ƒå¦‚ä¸‹ï¼š

- æ“ä½œç³»ç»Ÿ: Linux
- PaddlePaddle: 2.3
- PaddleOCR: Release/2.5
- text_renderer: master

ä¸‹è½½PaddlleOCRä»£ç å¹¶å®‰è£…ä¾èµ–åº“:
```bash
git clone -b dygraph https://gitee.com/paddlepaddle/PaddleOCR

# å®‰è£…ä¾èµ–åº“
cd PaddleOCR
pip install -r PaddleOCR/requirements.txt
```

## 3. æ•°æ®å‡†å¤‡

æœ¬é¡¹ç›®ä½¿ç”¨äººå·¥é¢„æ ‡æ³¨çš„300å¼ å›¾åƒä½œä¸ºæµ‹è¯•é›†ã€‚

éƒ¨åˆ†æ•°æ®ç¤ºä¾‹å¦‚ä¸‹ï¼š

![](https://ai-studio-static-online.cdn.bcebos.com/39ff30e0ab0442579712255e6a9ea6b5271169c98e624e6eb2b8781f003bfea0)


æ ‡ç­¾æ–‡ä»¶æ ¼å¼å¦‚ä¸‹ï¼š
```txt
æ•°æ®è·¯å¾„ æ ‡ç­¾ï¼ˆä¸­é—´ä»¥åˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
```

|æ•°æ®é›†ç±»å‹|æ•°é‡|
|---|---|
|æµ‹è¯•é›†| 300|

æ•°æ®é›†[ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/datasetdetail/149770)ï¼Œä¸‹è½½åå¯ä»¥é€šè¿‡ä¸‹æ–¹å‘½ä»¤è§£å‹:

```bash
tar -xvf data.tar
mv data ${PaddleOCR_root}
```

æ•°æ®è§£å‹åçš„æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š

```shell
PaddleOCR
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ mining_images            # æŒ–æ˜çš„çœŸå®æ•°æ®ç¤ºä¾‹
â”‚   â”œâ”€â”€ mining_train.list        # æŒ–æ˜çš„çœŸå®æ•°æ®æ–‡ä»¶åˆ—è¡¨
â”‚   â”œâ”€â”€ render_images            # åˆæˆæ•°æ®ç¤ºä¾‹
â”‚   â”œâ”€â”€ render_train.list        # åˆæˆæ•°æ®æ–‡ä»¶åˆ—è¡¨
â”‚   â”œâ”€â”€ val                      # æµ‹è¯•é›†æ•°æ®
â”‚   â””â”€â”€ val.list                 # æµ‹è¯•é›†æ•°æ®æ–‡ä»¶åˆ—è¡¨
|   â”œâ”€â”€ bg                       # åˆæˆæ•°æ®æ‰€éœ€èƒŒæ™¯å›¾åƒ
â”‚   â””â”€â”€ corpus                   # åˆæˆæ•°æ®æ‰€éœ€è¯­æ–™
```

## 4. ç›´æ¥ä½¿ç”¨PP-OCRv3æ¨¡å‹è¯„ä¼°

å‡†å¤‡å¥½æµ‹è¯•æ•°æ®åï¼Œå¯ä»¥ä½¿ç”¨PaddleOCRçš„PP-OCRv3æ¨¡å‹è¿›è¡Œè¯†åˆ«ã€‚

- ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

é¦–å…ˆéœ€è¦ä¸‹è½½PP-OCR v3ä¸­è‹±æ–‡è¯†åˆ«æ¨¡å‹æ–‡ä»¶ï¼Œä¸‹è½½é“¾æ¥å¯ä»¥åœ¨https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/doc/doc_ch/ppocr_introduction.md#6 è·å–ï¼Œä¸‹è½½å‘½ä»¤:

```bash
cd ${PaddleOCR_root}
mkdir ckpt
wget -nc -P ckpt https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_train.tar
pushd ckpt/
tar -xvf ch_PP-OCRv3_rec_train.tar
popd
```

- æ¨¡å‹è¯„ä¼°

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡ŒPP-OCRv3è¯„ä¼°:

```bash
python tools/eval.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec_distillation.yml \
                         -o Global.checkpoints=ckpt/ch_PP-OCRv3_rec_train/best_accuracy \
                         Eval.dataset.data_dir=./data \
                         Eval.dataset.label_file_list=["./data/val.list"]

```

å…¶ä¸­å„å‚æ•°å«ä¹‰å¦‚ä¸‹ï¼š

```bash
-c: æŒ‡å®šä½¿ç”¨çš„é…ç½®æ–‡ä»¶ï¼Œch_PP-OCRv3_rec_distillation.ymlå¯¹åº”äºOCRv3è¯†åˆ«æ¨¡å‹ã€‚
-o: è¦†ç›–é…ç½®æ–‡ä»¶ä¸­å‚æ•°
Global.checkpoints: æŒ‡å®šè¯„ä¼°ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„
Eval.dataset.data_dir: æŒ‡å®šè¯„ä¼°æ•°æ®é›†è·¯å¾„
Eval.dataset.label_file_list: æŒ‡å®šè¯„ä¼°æ•°æ®é›†æ–‡ä»¶åˆ—è¡¨
```

## 5. åŸºäºåˆæˆæ•°æ®finetune

### 5.1 Text Rendereræ•°æ®åˆæˆæ–¹æ³•

#### 5.1.1 ä¸‹è½½Text Rendererä»£ç 

é¦–å…ˆä»githubæˆ–giteeä¸‹è½½Text Rendererä»£ç ï¼Œå¹¶å®‰è£…ç›¸å…³ä¾èµ–ã€‚

```bash
git clone https://gitee.com/wowowoll/text_renderer.git

# å®‰è£…ä¾èµ–åº“
cd text_renderer
pip install -r requirements.txt
```

ä½¿ç”¨text rendereråˆæˆæ•°æ®ä¹‹å‰éœ€è¦å‡†å¤‡å¥½èƒŒæ™¯å›¾ç‰‡ã€è¯­æ–™ä»¥åŠå­—ä½“åº“ï¼Œä¸‹é¢å°†é€ä¸€ä»‹ç»å„ä¸ªæ­¥éª¤ã€‚

#### 5.1.2 å‡†å¤‡èƒŒæ™¯å›¾ç‰‡

è§‚å¯Ÿæ—¥å¸¸ç”Ÿæ´»ä¸­å¸¸è§çš„åŒ…è£…ç”Ÿäº§æ—¥æœŸå›¾ç‰‡ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°å…¶èƒŒæ™¯ç›¸å¯¹ç®€å•ã€‚ä¸ºæ­¤æˆ‘ä»¬å¯ä»¥ä»ç½‘ä¸Šæ‰¾ä¸€ä¸‹å›¾ç‰‡ï¼Œæˆªå–éƒ¨åˆ†å›¾åƒå—ä½œä¸ºèƒŒæ™¯å›¾åƒã€‚

æœ¬é¡¹ç›®å·²å‡†å¤‡äº†éƒ¨åˆ†å›¾åƒä½œä¸ºèƒŒæ™¯å›¾ç‰‡ï¼Œåœ¨ç¬¬3éƒ¨åˆ†å®Œæˆæ•°æ®å‡†å¤‡å,å¯ä»¥å¾—åˆ°æˆ‘ä»¬å‡†å¤‡å¥½çš„èƒŒæ™¯å›¾åƒï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

![](https://ai-studio-static-online.cdn.bcebos.com/456ae2acb27d4a94896c478812aee0bc3551c703d7bd40c9be4dc983c7b3fc8a)



èƒŒæ™¯å›¾åƒå­˜æ”¾äºå¦‚ä¸‹ä½ç½®ï¼š

```shell
PaddleOCR
â”œâ”€â”€ data
ï½œ   â”œâ”€â”€ bg     # åˆæˆæ•°æ®æ‰€éœ€èƒŒæ™¯å›¾åƒ
```

#### 5.1.3 å‡†å¤‡è¯­æ–™

è§‚å¯Ÿæµ‹è¯•é›†ç”Ÿäº§æ—¥æœŸå›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“å¦‚ä¸‹æ•°æ®æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š
1. ç”±å¹´æœˆæ—¥ç»„æˆï¼Œä¸­é—´å¯èƒ½ä»¥â€œ/â€ã€â€œ-â€ã€â€œ:â€ã€â€œ.â€æˆ–è€…ç©ºæ ¼é—´éš”ï¼Œä¹Ÿå¯èƒ½ä»¥æ±‰å­—å¹´æœˆæ—¥åˆ†éš”
2. æœ‰äº›ç”Ÿäº§æ—¥æœŸåŒ…å«åœ¨äº§å“æ‰¹å·ä¸­ï¼Œæ­¤æ—¶å¯èƒ½åŒ…å«å…·ä½“æ—¶é—´ã€è‹±æ–‡å­—æ¯æˆ–æ•°å­—æ ‡è¯†

åŸºäºä»¥ä¸Šä¸¤ç‚¹ï¼Œæˆ‘ä»¬ç¼–å†™è¯­æ–™ç”Ÿæˆè„šæœ¬ï¼š

```python
import random
from random import choice
import os

cropus_num = 2000 #è®¾ç½®è¯­æ–™æ•°é‡

def get_cropus(f):
    # éšæœºç”Ÿæˆå¹´ä»½
    year = random.randint(0, 22)
    # éšæœºç”Ÿæˆæœˆä»½
    month = random.randint(1, 12)
    # éšæœºç”Ÿæˆæ—¥æœŸ
    day_dict = {31: [1,3,5,7,8,10,12], 30: [4,6,9,11], 28: [2]}
    for item in day_dict:
        if month in day_dict[item]:
            day = random.randint(0, item)
    # éšæœºç”Ÿæˆå°æ—¶
    hours = random.randint(0, 24)
    # éšæœºç”Ÿæˆåˆ†é’Ÿ
    minute = random.randint(0, 60)
     # éšæœºç”Ÿæˆç§’æ•°
    second = random.randint(0, 60)

    # éšæœºç”Ÿæˆäº§å“æ ‡è¯†å­—ç¬¦
    length = random.randint(0, 6)
    file_id = []
    flag = 0
    my_dict = [i for i in range(48,58)] + [j for j in range(40, 42)] + [k for k in range(65,90)]  # å¤§å°å†™å­—æ¯ + æ‹¬å·

    for i in range(1, length):
        if flag:
            if i == flag+2:  #æ‹¬å·åŒ¹é…
                file_id.append(')')
                flag = 0
                continue
        sel = choice(my_dict)
        if sel == 41:
            continue
        if sel == 40:
            if i == 1 or i > length-3:
                continue
            flag = i
        my_ascii = chr(sel)
        file_id.append(my_ascii)
    file_id_str = ''.join(file_id)

    #éšæœºç”Ÿæˆäº§å“æ ‡è¯†å­—ç¬¦
    file_id2 = random.randint(0, 9)

    rad = random.random()
    if rad < 0.3:
        f.write('20{:02d}{:02d}{:02d} {}'.format(year, month, day, file_id_str))
    elif 0.3 < rad < 0.5:
        f.write('20{:02d}å¹´{:02d}æœˆ{:02d}æ—¥'.format(year, month, day))
    elif 0.5 < rad < 0.7:
        f.write('20{:02d}/{:02d}/{:02d}'.format(year, month, day))
    elif 0.7 < rad < 0.8:
        f.write('20{:02d}-{:02d}-{:02d}'.format(year, month, day))
    elif 0.8 < rad < 0.9:
        f.write('20{:02d}.{:02d}.{:02d}'.format(year, month, day))  
    else:
        f.write('{:02d}:{:02d}:{:02d} {:02d}'.format(hours, minute, second, file_id2))

if __name__ == "__main__":
    file_path = '/home/aistudio/text_renderer/my_data/cropus'
    if not os.path.exists(file_path):
        os.makedirs(file_path)
    file_name = os.path.join(file_path, 'books.txt')
    f = open(file_name, 'w')
    for i in range(cropus_num):
        get_cropus(f)
        if i < cropus_num-1:
            f.write('\n')

    f.close()
```

æœ¬é¡¹ç›®å·²å‡†å¤‡äº†éƒ¨åˆ†è¯­æ–™ï¼Œåœ¨ç¬¬3éƒ¨åˆ†å®Œæˆæ•°æ®å‡†å¤‡å,å¯ä»¥å¾—åˆ°æˆ‘ä»¬å‡†å¤‡å¥½çš„è¯­æ–™åº“ï¼Œé»˜è®¤ä½ç½®å¦‚ä¸‹ï¼š

```shell
PaddleOCR
â”œâ”€â”€ data
â”‚   â””â”€â”€ corpus              #åˆæˆæ•°æ®æ‰€éœ€è¯­æ–™
```

#### 5.1.4 ä¸‹è½½å­—ä½“

è§‚å¯ŸåŒ…è£…ç”Ÿäº§æ—¥æœŸï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°å…¶ä½¿ç”¨çš„å­—ä½“ä¸ºç‚¹é˜µä½“ã€‚å­—ä½“å¯ä»¥åœ¨å¦‚ä¸‹ç½‘å€ä¸‹è½½ï¼š
https://www.fonts.net.cn/fonts-en/tag-dianzhen-1.html

æœ¬é¡¹ç›®å·²å‡†å¤‡äº†éƒ¨åˆ†å­—ä½“ï¼Œåœ¨ç¬¬3éƒ¨åˆ†å®Œæˆæ•°æ®å‡†å¤‡å,å¯ä»¥å¾—åˆ°æˆ‘ä»¬å‡†å¤‡å¥½çš„å­—ä½“ï¼Œé»˜è®¤ä½ç½®å¦‚ä¸‹ï¼š

```shell
PaddleOCR
â”œâ”€â”€ data
â”‚   â””â”€â”€ fonts                #åˆæˆæ•°æ®æ‰€éœ€å­—ä½“
```

ä¸‹è½½å¥½å­—ä½“åï¼Œè¿˜éœ€è¦åœ¨listæ–‡ä»¶ä¸­æŒ‡å®šå­—ä½“æ–‡ä»¶å­˜æ”¾è·¯å¾„ï¼Œè„šæœ¬å¦‚ä¸‹:

```bash
cd text_renderer/my_data/
touch fonts.list
ls /home/aistudio/PaddleOCR/data/fonts/* > fonts.list
```

#### 5.1.5 è¿è¡Œæ•°æ®åˆæˆå‘½ä»¤

å®Œæˆæ•°æ®å‡†å¤‡åï¼Œmy_dataæ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š

```shell
my_data/
â”œâ”€â”€ cropus
â”‚   â””â”€â”€ books.txt #è¯­æ–™åº“
â”œâ”€â”€ eng.txt    #å­—ç¬¦åˆ—è¡¨
â””â”€â”€ fonts.list #å­—ä½“åˆ—è¡¨
```

åœ¨è¿è¡Œåˆæˆæ•°æ®å‘½ä»¤ä¹‹å‰ï¼Œè¿˜æœ‰ä¸¤å¤„ç»†èŠ‚éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ï¼š
1. å°†é»˜è®¤é…ç½®æ–‡ä»¶`text_renderer/configs/default.yaml`ä¸­ç¬¬9è¡Œenableçš„å€¼è®¾ä¸º`true`ï¼Œå³å…è®¸åˆæˆå½©è‰²å›¾åƒã€‚å¦åˆ™åˆæˆçš„éƒ½æ˜¯ç°åº¦å›¾ã€‚

```yaml
 # color boundary is in R,G,B format
 font_color:
+  enable: true #false
```

2. å°†`text_renderer/textrenderer/renderer.py`ç¬¬184è¡Œä½œå¦‚ä¸‹ä¿®æ”¹ï¼Œå–æ¶ˆpaddingã€‚å¦åˆ™å›¾ç‰‡ä¸¤ç«¯ä¼šæœ‰ä¸€äº›ç©ºç™½ã€‚

```python
padding = random.randint(s_bbox_width // 10, s_bbox_width // 8) #ä¿®æ”¹å‰
padding = 0 #ä¿®æ”¹å
```

è¿è¡Œæ•°æ®åˆæˆå‘½ä»¤:

```bash
cd /home/aistudio/text_renderer/
python main.py --num_img=3000 \
                  --fonts_list='./my_data/fonts.list' \
                  --corpus_dir "./my_data/cropus" \
                  --corpus_mode "list" \
                  --bg_dir "/home/aistudio/PaddleOCR/data/bg/" \
                  --img_width 0
```

åˆæˆå¥½çš„æ•°æ®é»˜è®¤ä¿å­˜åœ¨`text_renderer/output`ç›®å½•ä¸‹ï¼Œå¯è¿›å…¥è¯¥ç›®å½•æŸ¥çœ‹åˆæˆçš„æ•°æ®ã€‚


åˆæˆæ•°æ®ç¤ºä¾‹å¦‚ä¸‹
![](https://ai-studio-static-online.cdn.bcebos.com/d686a48d465a43d09fbee51924fdca42ee21c50e676646da8559fb9967b94185)

æ•°æ®åˆæˆå¥½åï¼Œè¿˜éœ€è¦ç”Ÿæˆå¦‚ä¸‹æ ¼å¼çš„è®­ç»ƒæ‰€éœ€çš„æ ‡æ³¨æ–‡ä»¶ï¼Œ
```
å›¾åƒè·¯å¾„ æ ‡ç­¾
```

ä½¿ç”¨å¦‚ä¸‹è„šæœ¬å³å¯ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶ï¼š

```python
import random

abspath = '/home/aistudio/text_renderer/output/default/'

#æ ‡æ³¨æ–‡ä»¶ç”Ÿæˆè·¯å¾„
fout = open('./render_train.list', 'w', encoding='utf-8')

with open('./output/default/tmp_labels.txt','r') as f:
    lines = f.readlines()
    for item in lines:
        label = item[9:]
        filename = item[:8] + '.jpg'
        fout.write(abspath + filename + '\t' + label)

    fout.close()
```

ç»è¿‡ä»¥ä¸Šæ­¥éª¤ï¼Œæˆ‘ä»¬ä¾¿å®Œæˆäº†åŒ…è£…ç”Ÿäº§æ—¥æœŸæ•°æ®åˆæˆã€‚
æ•°æ®ä½äº`text_renderer/output`ï¼Œæ ‡æ³¨æ–‡ä»¶ä½äº`text_renderer/render_train.list`ã€‚

æœ¬é¡¹ç›®æä¾›äº†ç”Ÿæˆå¥½çš„æ•°æ®ä¾›å¤§å®¶ä½“éªŒ,å®Œæˆæ­¥éª¤3çš„æ•°æ®å‡†å¤‡åï¼Œå¯å¾—æ•°æ®è·¯å¾„ä½äº:

```shell
PaddleOCR
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ render_images     # åˆæˆæ•°æ®ç¤ºä¾‹
â”‚   â”œâ”€â”€ render_train.list   #åˆæˆæ•°æ®æ–‡ä»¶åˆ—è¡¨
```

###  5.2 æ¨¡å‹è®­ç»ƒ

å‡†å¤‡å¥½åˆæˆæ•°æ®åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼Œåˆ©ç”¨åˆæˆæ•°æ®è¿›è¡Œfinetune:
```bash
cd ${PaddleOCR_root}
python tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec_distillation.yml \
                       -o Global.pretrained_model=./ckpt/ch_PP-OCRv3_rec_train/best_accuracy \
                       Global.epoch_num=20 \
                       Global.eval_batch_step='[0, 20]' \
                       Train.dataset.data_dir=./data \
                       Train.dataset.label_file_list=['./data/render_train.list'] \
                       Train.loader.batch_size_per_card=64 \
                       Eval.dataset.data_dir=./data \
                       Eval.dataset.label_file_list=["./data/val.list"] \
                       Eval.loader.batch_size_per_card=64

```

å…¶ä¸­å„å‚æ•°å«ä¹‰å¦‚ä¸‹ï¼š

```txt
-c: æŒ‡å®šä½¿ç”¨çš„é…ç½®æ–‡ä»¶ï¼Œch_PP-OCRv3_rec_distillation.ymlå¯¹åº”äºOCRv3è¯†åˆ«æ¨¡å‹ã€‚
-o: è¦†ç›–é…ç½®æ–‡ä»¶ä¸­å‚æ•°
Global.pretrained_model: æŒ‡å®šfinetuneä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹
Global.epoch_num: æŒ‡å®šè®­ç»ƒçš„epochæ•°
Global.eval_batch_step: é—´éš”å¤šå°‘stepåšä¸€æ¬¡è¯„ä¼°
Train.dataset.data_dir: è®­ç»ƒæ•°æ®é›†è·¯å¾„
Train.dataset.label_file_list: è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨
Train.loader.batch_size_per_card: è®­ç»ƒå•å¡batch size
Eval.dataset.data_dir: è¯„ä¼°æ•°æ®é›†è·¯å¾„
Eval.dataset.label_file_list: è¯„ä¼°æ•°æ®é›†æ–‡ä»¶åˆ—è¡¨
Eval.loader.batch_size_per_card: è¯„ä¼°å•å¡batch size
```

## 6. åŸºäºçœŸå®æ•°æ®finetune


ä½¿ç”¨åˆæˆæ•°æ®finetuneèƒ½æå‡æˆ‘ä»¬æ¨¡å‹çš„è¯†åˆ«ç²¾åº¦ï¼Œä½†ç”±äºåˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´çš„åˆ†å¸ƒå¯èƒ½æœ‰ä¸€å®šå·®å¼‚ï¼Œå› æ­¤ä½œç”¨æœ‰é™ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜è¯†åˆ«ç²¾åº¦ï¼Œæœ¬èŠ‚ä»‹ç»å¦‚ä½•æŒ–æ˜çœŸå®æ•°æ®è¿›è¡Œæ¨¡å‹finetuneã€‚

æ•°æ®æŒ–æ˜çš„æ•´ä½“æ€è·¯å¦‚ä¸‹ï¼š
1. ä½¿ç”¨pythonçˆ¬è™«ä»ç½‘ä¸Šè·å–å¤§é‡æ— æ ‡ç­¾æ•°æ®
2. ä½¿ç”¨æ¨¡å‹ä»å¤§é‡æ— æ ‡ç­¾æ•°æ®ä¸­æ„å»ºå‡ºæœ‰æ•ˆè®­ç»ƒé›†

### 6.1 pythonçˆ¬è™«è·å–æ•°æ®

- æ¨èä½¿ç”¨[çˆ¬è™«å·¥å…·](https://github.com/Joeclinton1/google-images-download)è·å–æ— æ ‡ç­¾å›¾ç‰‡ã€‚

å›¾ç‰‡è·å–åï¼Œå¯æŒ‰å¦‚ä¸‹ç›®å½•æ ¼å¼ç»„ç»‡ï¼š

```txt
sprider
â”œâ”€â”€ file.list
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ 00000.jpg
â”‚   â”œâ”€â”€ 00001.jpg
...
```

### 6.2 æ•°æ®æŒ–æ˜

æˆ‘ä»¬ä½¿ç”¨PaddleOCRå¯¹è·å–åˆ°çš„å›¾ç‰‡è¿›è¡ŒæŒ–æ˜ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š
1. ä½¿ç”¨ PP-OCRv3æ£€æµ‹æ¨¡å‹+svtr-tinyè¯†åˆ«æ¨¡å‹ï¼Œå¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹ã€‚
2. ä½¿ç”¨æ•°æ®æŒ–æ˜ç­–ç•¥ï¼Œå¾—åˆ°æœ‰æ•ˆå›¾ç‰‡ã€‚
3. å°†æœ‰æ•ˆå›¾ç‰‡å¯¹åº”çš„å›¾åƒåŒºåŸŸå’Œæ ‡ç­¾æå–å‡ºæ¥ï¼Œæ„å»ºè®­ç»ƒé›†ã€‚


é¦–å…ˆä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ŒPP-OCRv3æ£€æµ‹æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼šhttps://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar

å¦‚éœ€è·å–svtr-tinyé«˜ç²¾åº¦ä¸­æ–‡è¯†åˆ«é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·æ‰«ç å¡«å†™é—®å·ï¼ŒåŠ å…¥PaddleOCRå®˜æ–¹äº¤æµç¾¤è·å–å…¨éƒ¨OCRå‚ç±»æ¨¡å‹ä¸‹è½½é“¾æ¥ã€ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ç­‰å…¨å¥—OCRå­¦ä¹ èµ„æ–™ğŸ
<div align="left">
<img src="https://ai-studio-static-online.cdn.bcebos.com/dd721099bd50478f9d5fb13d8dd00fad69c22d6848244fd3a1d3980d7fefc63e"  width = "150" height = "150" />
</div>


å®Œæˆä¸‹è½½åï¼Œå¯å°†æ¨¡å‹å­˜å‚¨äºå¦‚ä¸‹ä½ç½®:

```shell
PaddleOCR
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ rec_vit_sub_64_363_all/  # svtr_tinyé«˜ç²¾åº¦è¯†åˆ«æ¨¡å‹
```

```bash
# ä¸‹è½½è§£å‹PP-OCRv3æ£€æµ‹æ¨¡å‹
cd ${PaddleOCR_root}
wget -nc -P ckpt https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar
pushd ckpt
tar -xvf ch_PP-OCRv3_det_infer.tar
popd ckpt
```

åœ¨ä½¿ç”¨PPOCRv3æ£€æµ‹æ¨¡å‹+svtr-tinyè¯†åˆ«æ¨¡å‹è¿›è¡Œé¢„æµ‹ä¹‹å‰ï¼Œæœ‰å¦‚ä¸‹ä¸¤å¤„ç»†èŠ‚éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ï¼š
1. å°†`tools/infer/predict_rec.py`ä¸­ç¬¬110è¡Œ`imgW`ä¿®æ”¹ä¸º`320`

```python
#imgW = int((imgH * max_wh_ratio))
imgW = 320
```

2. å°†`tools/infer/predict_system.py`ç¬¬169è¡Œæ·»åŠ å¦‚ä¸‹ä¸€è¡Œï¼Œå°†é¢„æµ‹åˆ†æ•°ä¹Ÿå†™å…¥ç»“æœæ–‡ä»¶ä¸­ã€‚

```python
"scores": rec_res[idx][1],
```

æ¨¡å‹é¢„æµ‹å‘½ä»¤:
```bash
python tools/infer/predict_system.py \
        --image_dir="/home/aistudio/sprider/data" \
        --det_model_dir="./ckpt/ch_PP-OCRv3_det_infer/"  \
        --rec_model_dir="/home/aistudio/PaddleOCR/data/rec_vit_sub_64_363_all/" \
        --rec_image_shape="3,32,320"
```

è·å¾—é¢„æµ‹ç»“æœåï¼Œæˆ‘ä»¬ä½¿ç”¨æ•°æ®æŒ–æ˜ç­–ç•¥å¾—åˆ°æœ‰æ•ˆå›¾ç‰‡ã€‚å…·ä½“æŒ–æ˜ç­–ç•¥å¦‚ä¸‹ï¼š
1. é¢„æµ‹ç½®ä¿¡åº¦é«˜äº95%
2. è¯†åˆ«ç»“æœåŒ…å«å­—ç¬¦â€˜20â€™ï¼Œå³å¹´ä»½
3. æ²¡æœ‰ä¸­æ–‡ï¼Œæˆ–è€…æœ‰ä¸­æ–‡å¹¶ä¸”â€˜æ—¥â€™å’Œ'æœˆ'åŒæ—¶åœ¨è¯†åˆ«ç»“æœä¸­

```python
# è·å–æœ‰æ•ˆé¢„æµ‹

import json
import re

zh_pattern = re.compile(u'[\u4e00-\u9fa5]+')  #æ­£åˆ™è¡¨è¾¾å¼ï¼Œç­›é€‰å­—ç¬¦æ˜¯å¦åŒ…å«ä¸­æ–‡

file_path = '/home/aistudio/PaddleOCR/inference_results/system_results.txt'
out_path = '/home/aistudio/PaddleOCR/selected_results.txt'
f_out = open(out_path, 'w')

with open(file_path, "r", encoding='utf-8') as fin:
    lines = fin.readlines()


for line in lines:
    flag = False
    # è¯»å–æ–‡ä»¶å†…å®¹
    file_name, json_file = line.strip().split('\t')
    preds = json.loads(json_file)
    res = []
    for item in preds:
        transcription = item['transcription'] #è·å–è¯†åˆ«ç»“æœ
        scores = item['scores']               #è·å–è¯†åˆ«å¾—åˆ†
        # æŒ–æ˜ç­–ç•¥
        if scores > 0.95:
            if '20' in transcription and len(transcription) > 4 and len(transcription) < 12:
                word = transcription
                if not(zh_pattern.search(word) and ('æ—¥' not in word or 'æœˆ' not in word)):
                    flag = True
                    res.append(item)
    save_pred = file_name + "\t" + json.dumps(
        res, ensure_ascii=False) + "\n"
    if flag ==True:
        f_out.write(save_pred)

f_out.close()
```

ç„¶åå°†æœ‰æ•ˆé¢„æµ‹å¯¹åº”çš„å›¾åƒåŒºåŸŸå’Œæ ‡ç­¾æå–å‡ºæ¥ï¼Œæ„å»ºè®­ç»ƒé›†ã€‚å…·ä½“å®ç°è„šæœ¬å¦‚ä¸‹ï¼š

```python
import cv2
import json
import numpy as np

PATH = '/home/aistudio/PaddleOCR/inference_results/'  #æ•°æ®åŸå§‹è·¯å¾„
SAVE_PATH = '/home/aistudio/mining_images/'             #è£å‰ªåæ•°æ®ä¿å­˜è·¯å¾„
file_list = '/home/aistudio/PaddleOCR/selected_results.txt' #æ•°æ®é¢„æµ‹ç»“æœ
label_file = '/home/aistudio/mining_images/mining_train.list'  #è¾“å‡ºçœŸå®æ•°æ®è®­ç»ƒé›†æ ‡ç­¾list

if not os.path.exists(SAVE_PATH):
    os.mkdir(SAVE_PATH)

f_label = open(label_file, 'w')


def get_rotate_crop_image(img, points):
    """
    æ ¹æ®æ£€æµ‹ç»“æœpointsï¼Œä»è¾“å…¥å›¾åƒimgä¸­è£å‰ªå‡ºç›¸åº”çš„åŒºåŸŸ
    """
    assert len(points) == 4, "shape of points must be 4*2"
    img_crop_width = int(
        max(
            np.linalg.norm(points[0] - points[1]),
            np.linalg.norm(points[2] - points[3])))
    img_crop_height = int(
        max(
            np.linalg.norm(points[0] - points[3]),
            np.linalg.norm(points[1] - points[2])))
    pts_std = np.float32([[0, 0], [img_crop_width, 0],
                          [img_crop_width, img_crop_height],
                          [0, img_crop_height]])
    M = cv2.getPerspectiveTransform(points, pts_std)
    # å½¢å˜æˆ–å€¾æ–œï¼Œä¼šåšé€è§†å˜æ¢ï¼ŒreshapeæˆçŸ©å½¢
    dst_img = cv2.warpPerspective(
        img,
        M, (img_crop_width, img_crop_height),
        borderMode=cv2.BORDER_REPLICATE,
        flags=cv2.INTER_CUBIC)
    dst_img_height, dst_img_width = dst_img.shape[0:2]
    if dst_img_height * 1.0 / dst_img_width >= 1.5:
        dst_img = np.rot90(dst_img)
    return dst_img

def crop_and_get_filelist(file_list):
    with open(file_list, "r", encoding='utf-8') as fin:
        lines = fin.readlines()

    img_num = 0
    for line in lines:
        img_name, json_file = line.strip().split('\t')
        preds = json.loads(json_file)
        for item in preds:
            transcription = item['transcription']
            points = item['points']
            points = np.array(points).astype('float32')
            #print('processing {}...'.format(img_name))

            img = cv2.imread(PATH+img_name)
            dst_img = get_rotate_crop_image(img, points)
            h, w, c = dst_img.shape
            newWidth = int((32. / h) * w)
            newImg = cv2.resize(dst_img, (newWidth, 32))
            new_img_name = '{:05d}.jpg'.format(img_num)
            cv2.imwrite(SAVE_PATH+new_img_name, dst_img)
            f_label.write(SAVE_PATH+new_img_name+'\t'+transcription+'\n')
            img_num += 1


crop_and_get_filelist(file_list)
f_label.close()
```

### 6.3 æ¨¡å‹è®­ç»ƒ

é€šè¿‡æ•°æ®æŒ–æ˜ï¼Œæˆ‘ä»¬å¾—åˆ°äº†çœŸå®åœºæ™¯æ•°æ®å’Œå¯¹åº”çš„æ ‡ç­¾ã€‚æ¥ä¸‹æ¥ä½¿ç”¨çœŸå®æ•°æ®finetuneï¼Œè§‚å¯Ÿç²¾åº¦æå‡æ•ˆæœã€‚


åˆ©ç”¨çœŸå®æ•°æ®è¿›è¡Œfinetune:

```bash
cd ${PaddleOCR_root}
python tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec_distillation.yml \
                       -o Global.pretrained_model=./ckpt/ch_PP-OCRv3_rec_train/best_accuracy \
                       Global.epoch_num=20 \
                       Global.eval_batch_step='[0, 20]' \
                       Train.dataset.data_dir=./data \
                       Train.dataset.label_file_list=['./data/mining_train.list'] \
                       Train.loader.batch_size_per_card=64 \
                       Eval.dataset.data_dir=./data \
                       Eval.dataset.label_file_list=["./data/val.list"] \
                       Eval.loader.batch_size_per_card=64
```

å„å‚æ•°å«ä¹‰å‚è€ƒç¬¬6éƒ¨åˆ†åˆæˆæ•°æ®finetuneï¼Œåªéœ€è¦å¯¹è®­ç»ƒæ•°æ®è·¯å¾„åšç›¸åº”çš„ä¿®æ”¹ï¼š

```txt
Train.dataset.data_dir: è®­ç»ƒæ•°æ®é›†è·¯å¾„
Train.dataset.label_file_list: è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨
```

ç¤ºä¾‹ä½¿ç”¨æˆ‘ä»¬æä¾›çš„çœŸå®æ•°æ®è¿›è¡Œfinetuneï¼Œå¦‚æƒ³æ¢æˆè‡ªå·±çš„æ•°æ®ï¼Œåªéœ€è¦ç›¸åº”çš„ä¿®æ”¹`Train.dataset.data_dir`å’Œ`Train.dataset.label_file_list`å‚æ•°å³å¯ã€‚

ç”±äºæ•°æ®é‡ä¸å¤§ï¼Œè¿™é‡Œä»…è®­ç»ƒ20ä¸ªepochå³å¯ã€‚è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥å¾—åˆ°åˆæˆæ•°æ®finetuneåçš„ç²¾åº¦ä¸ºbest acc=**71.33%**ã€‚

ç”±äºæ•°é‡æ¯”è¾ƒå°‘ï¼Œç²¾åº¦ä¼šæ¯”åˆæˆæ•°æ®finetueçš„ç•¥ä½ã€‚


## 7. åŸºäºåˆæˆ+çœŸå®æ•°æ®finetune

ä¸ºè¿›ä¸€æ­¥æå‡æ¨¡å‹ç²¾åº¦ï¼Œæˆ‘ä»¬ç»“åˆä½¿ç”¨åˆæˆæ•°æ®å’ŒæŒ–æ˜åˆ°çš„çœŸå®æ•°æ®è¿›è¡Œfinetuneã€‚

åˆ©ç”¨åˆæˆ+çœŸå®æ•°æ®è¿›è¡Œfinetuneï¼Œå„å‚æ•°å«ä¹‰å‚è€ƒç¬¬6éƒ¨åˆ†åˆæˆæ•°æ®finetuneï¼Œåªéœ€è¦å¯¹è®­ç»ƒæ•°æ®è·¯å¾„åšç›¸åº”çš„ä¿®æ”¹ï¼š

```txt
Train.dataset.data_dir: è®­ç»ƒæ•°æ®é›†è·¯å¾„
Train.dataset.label_file_list: è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨
```

ç”Ÿæˆè®­ç»ƒlistæ–‡ä»¶:
```bash
# ç”Ÿæˆè®­ç»ƒé›†æ–‡ä»¶list
cat /home/aistudio/PaddleOCR/data/render_train.list /home/aistudio/PaddleOCR/data/mining_train.list > /home/aistudio/PaddleOCR/data/render_mining_train.list
```

å¯åŠ¨è®­ç»ƒ:
```bash
cd ${PaddleOCR_root}
python tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec_distillation.yml \
                       -o Global.pretrained_model=./ckpt/ch_PP-OCRv3_rec_train/best_accuracy \
                       Global.epoch_num=40 \
                       Global.eval_batch_step='[0, 20]' \
                       Train.dataset.data_dir=./data \
                       Train.dataset.label_file_list=['./data/render_mining_train.list'] \
                       Train.loader.batch_size_per_card=64 \
                       Eval.dataset.data_dir=./data \
                       Eval.dataset.label_file_list=["./data/val.list"] \
                       Eval.loader.batch_size_per_card=64
```

ç¤ºä¾‹ä½¿ç”¨æˆ‘ä»¬æä¾›çš„çœŸå®+åˆæˆæ•°æ®è¿›è¡Œfinetuneï¼Œå¦‚æƒ³æ¢æˆè‡ªå·±çš„æ•°æ®ï¼Œåªéœ€è¦ç›¸åº”çš„ä¿®æ”¹Train.dataset.data_dirå’ŒTrain.dataset.label_file_listå‚æ•°å³å¯ã€‚

ç”±äºæ•°æ®é‡ä¸å¤§ï¼Œè¿™é‡Œä»…è®­ç»ƒ40ä¸ªepochå³å¯ã€‚è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥å¾—åˆ°åˆæˆæ•°æ®finetuneåçš„ç²¾åº¦ä¸ºbest acc=**86.99%**ã€‚

å¯ä»¥çœ‹åˆ°ï¼Œç›¸è¾ƒäºåŸå§‹PP-OCRv3çš„è¯†åˆ«ç²¾åº¦62.99%ï¼Œä½¿ç”¨åˆæˆæ•°æ®+çœŸå®æ•°æ®finetuneåï¼Œè¯†åˆ«ç²¾åº¦èƒ½æå‡24%ã€‚

å¦‚éœ€è·å–å·²è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥åŒæ ·æ‰«æä¸Šæ–¹äºŒç»´ç ä¸‹è½½ï¼Œå°†ä¸‹è½½æˆ–è®­ç»ƒå®Œæˆçš„æ¨¡å‹æ”¾ç½®åœ¨å¯¹åº”ç›®å½•ä¸‹å³å¯å®Œæˆæ¨¡å‹æ¨ç†ã€‚

æ¨¡å‹çš„æ¨ç†éƒ¨ç½²æ–¹æ³•å¯ä»¥å‚è€ƒrepoæ–‡æ¡£ï¼š https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/deploy/README_ch.md
